{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 4\n",
    "\n",
    "This assigment will be graded if everything works well. I will run the script as once and everything should be done without errors and mistakes. I should be able to run your scripts in my computer and get all the results. **USE RELATIVE PATHS**. An error or exception or anything that breaks the code will means NO GRADE (0). Additionally, you are not able to modify any file handly. It also means NO GRADE (0). Comment everything you think will help others read your script. We expect 0 errors using GitHub. Everything will be graded!\n",
    "\n",
    "**ASK EVERYTHING! WE ARE HERE TO HELP YOU!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this path **..\\_data\\sbs\\B_RawData\\bancos** you will find scraped data from [this link](https://www.sbs.gob.pe/app/pp/EstadisticasSAEEPortal/Paginas/TIActivaTipoCreditoEmpresa.aspx?tip=B). We get all the information of the last available day of every each month.\n",
    "\n",
    "1. Import all the data and generate a column named as `date_info` that should have the day to information corresponds.\n",
    "2. Append all this datasets and generate a unique dataframe. This newdataset should have information at `rate interest` and `date` level. The columns should be the name of the banks. Be careful since not all the excel files have the same format. **It is totally prohibited to manipulate manually the excel files. This kind of action means NO GRADE on this project.**\n",
    "3. What are the top 5 banks each year with the highest interest rate at `Préstamos hipotecarios para vivienda`, `Consumo -\n",
    "Tarjetas de Crédito`. Present a dataframe with these variables: `year`, `rate_concept`, `banks`, `rate_value`.\n",
    "4. We want to save this dataset in the folder **_output/sbs/group_#**, but we want to save a file per bank. We want to have the information disaggregated at the bank level. Please, save your files with the name of the bank. Avoid blank spaces and use only lowercase letters. Generate the folder of your group using python code. **Hint: os library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 1:\n",
    "Since we know that all the files in the given directory are `.xlsx` files, we get a list with the names of all the files in the directory using `os.listdir` function. Also, using map we trim the name so we get just the numbers that refer to the date of the file. <br>\n",
    "Then, we create an empty dictionary and, using a `for loop` and the prior list, we import each database in a key of the dictionary. In the same loop, we add a column with the date information of the database. We get the date formating the strings of the list we just create, first we use the `datetime.strptime` function to change the type of the string and, then, the `date` method to select just the date information (not the time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_files = [*map(lambda x: x[12:-5], os.listdir('../../_data/sbs/B_RawData/bancos'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for x in xlsx_files:\n",
    "    d[\"table_\"+x] = pd.read_excel(r'../../_data/sbs/B_RawData/bancos/table_clean_'+x+'.xlsx')\n",
    "    d[\"table_\"+x][\"date_info\"] = datetime.strptime(x, \"%d_%m_%Y\").date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 2:\n",
    "This answer is segmented in three parts: i) identification of the different structures in the dataframes, ii) homogenize all the dataframes and iii) append the dataframes in a bigger dataframe.\n",
    "\n",
    "<b>Identification of the different structures in the dataframes: </b>\n",
    "The idea is evaluate which dataframes has a structure different than the desired (bank's names as column names). We could know which structure has by searching for the name of the second column in each dataframe. To obtain complete information we follow the next process:\n",
    "1. We start creating an empty dataframe with two columns (one for the second column name and the other for the date of the dataframe).\n",
    "2. We usea a `for loop` to complete de previous empty dataframe with the information of the column name and the date of the database.\n",
    "3. We sort the resulting dataframe by the date (`Fecha` column)\n",
    "4. Finally, using another `for loop`, we print sentences indicating the name of the second column and the date of the given dataframe. <br>\n",
    "\n",
    "In the output we can identify four groups of different structures. The first structure starts on 30/09/2002 and ends on 30/04/2008, the second starts on 30/05/2008 and ends on 31/08/2010, the third starts on 30/09/2010 and ends on 31/05/2009, and the fourth starts on 28/06/2009 and ends on 31/08/2022. Also the first dataframe (from 31/03/2001) belongs to the fourth group. Knowing that means that we only need to look at one dataframe for each group to know how we must modify each of the dataframes. <br>\n",
    "\n",
    "<b>Homogenize all the dataframes: </b>\n",
    "From the previous step we could identify four different structures. The first and second structure have all the banks as rows and the rate concept as columns, being this opposite of our target. Also, both have the true rate concept in the second row. Additionally, only the second group has one extra problem: the rate values from each bank were displaced one row down. We identify that this displacement starts in the row named `Tarjetas de Crédito`.\n",
    "About the third and fourth groups, both have the same structure, the main difference were the use of different names to refeer to the same banks. This is actually a problem between all groups, so it is necessary to determine an homogeneous name for each of them.\n",
    "To solve this problems we made a `for loop` that goes through each dataframe and, by an `if statement`, identify which process should follow depending of which group it belongs (this according to the date of the information).\n",
    "\n",
    "- For the first group:\n",
    "1. Assign the values of the second row as the column names also assign the name `Tasa Anual (%)` to the first column.\n",
    "2. Drop the first two rows of the dataframe (since we no longer need them).\n",
    "3. Transpose the dataframe and reset the index so we have the structure desired.\n",
    "4. Assign the values of the first row as the column names.\n",
    "5. Drop the first and last row values (last row contains the date information).\n",
    "6. Generate a new column with the date information (as we made in the previous exercise).\n",
    "7. Erase some words of the column names in order to homogenize with the names of the fourth group (this reduce the number of columns to rename).\n",
    "8. Rename some column names in order to homogenize.\n",
    "9. Change the names of banks that through the years changed their names.\n",
    "\n",
    "- For the second group: <br>\n",
    "We made exactly the same process that we made for the previous group, but before the 6th step (generate date column) we make two new steps:\n",
    "1. Create an object named `pos` that indicates the row in which appears the value `Tarjetas de Crédito` in the second column. This will help us to know from which row we need to displace the portion of the dataframe.\n",
    "2. Move the values from all the rows after the one indicated in `pos` one column to the right. This resolve the displacement in the dataframes.\n",
    "\n",
    "- For the third and fourth group:\n",
    "1. Change the names of each bank to upper case, this is made in order of have equality through the dataframes. The columns that does not have names of banks does not change.\n",
    "2. Replace the names of three banks to match the one establiched for the other dataframes.\n",
    "3. Remove extra characters from some names using regular expressions. Again, this is in order to match the other dataframes\n",
    "4. Change the names of banks that through the years changed their names.\n",
    "\n",
    "<b>Append the dataframes in a bigger dataframe: </b>\n",
    "Once we have all the dataframes with the same structure, we proceed to append all of them. First we use make a copy of the first of the dataframe in a new one named `data_rates` and change the order of the columns selecting `Tasa Anual (%)` and `date_info` as the first. Then, using a `for loop` and the `pd.concat` function we append all the remaining dataframes to `data_rates`. Finally, we use another `for loop` that goes through each column changing to missing values all the values that match to `-` and `s.i.` and converting them into numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second  column: [BBVA] y date: [2001-03-31]\n",
      "Second  column: [COMERCIAL] y date: [2002-09-30]\n",
      "Second  column: [COMERCIAL] y date: [2002-10-31]\n",
      "Second  column: [COMERCIAL] y date: [2002-11-29]\n",
      "Second  column: [COMERCIAL] y date: [2002-12-31]\n",
      "Second  column: [COMERCIAL] y date: [2003-01-31]\n",
      "Second  column: [COMERCIAL] y date: [2003-02-28]\n",
      "Second  column: [COMERCIAL] y date: [2003-03-31]\n",
      "Second  column: [COMERCIAL] y date: [2003-04-30]\n",
      "Second  column: [COMERCIAL] y date: [2003-05-30]\n",
      "Second  column: [COMERCIAL] y date: [2003-06-30]\n",
      "Second  column: [COMERCIAL] y date: [2003-07-31]\n",
      "Second  column: [COMERCIAL] y date: [2003-08-29]\n",
      "Second  column: [COMERCIAL] y date: [2003-09-30]\n",
      "Second  column: [COMERCIAL] y date: [2003-10-31]\n",
      "Second  column: [COMERCIAL] y date: [2003-11-28]\n",
      "Second  column: [COMERCIAL] y date: [2003-12-31]\n",
      "Second  column: [COMERCIAL] y date: [2004-01-29]\n",
      "Second  column: [COMERCIAL] y date: [2004-02-26]\n",
      "Second  column: [COMERCIAL] y date: [2004-03-31]\n",
      "Second  column: [COMERCIAL] y date: [2004-04-30]\n",
      "Second  column: [COMERCIAL] y date: [2004-05-31]\n",
      "Second  column: [COMERCIAL] y date: [2004-06-30]\n",
      "Second  column: [COMERCIAL] y date: [2004-07-30]\n",
      "Second  column: [COMERCIAL] y date: [2004-08-31]\n",
      "Second  column: [COMERCIAL] y date: [2004-09-30]\n",
      "Second  column: [COMERCIAL] y date: [2004-10-29]\n",
      "Second  column: [COMERCIAL] y date: [2004-11-30]\n",
      "Second  column: [COMERCIAL] y date: [2004-12-31]\n",
      "Second  column: [COMERCIAL] y date: [2005-01-31]\n",
      "Second  column: [COMERCIAL] y date: [2005-02-28]\n",
      "Second  column: [COMERCIAL] y date: [2005-03-31]\n",
      "Second  column: [COMERCIAL] y date: [2005-04-29]\n",
      "Second  column: [COMERCIAL] y date: [2005-05-31]\n",
      "Second  column: [COMERCIAL] y date: [2005-06-30]\n",
      "Second  column: [COMERCIAL] y date: [2005-07-27]\n",
      "Second  column: [COMERCIAL] y date: [2005-08-31]\n",
      "Second  column: [COMERCIAL] y date: [2005-09-30]\n",
      "Second  column: [COMERCIAL] y date: [2005-10-31]\n",
      "Second  column: [COMERCIAL] y date: [2005-11-29]\n",
      "Second  column: [COMERCIAL] y date: [2005-12-30]\n",
      "Second  column: [COMERCIAL] y date: [2006-01-31]\n",
      "Second  column: [COMERCIAL] y date: [2006-02-28]\n",
      "Second  column: [COMERCIAL] y date: [2006-03-31]\n",
      "Second  column: [COMERCIAL] y date: [2006-04-28]\n",
      "Second  column: [COMERCIAL] y date: [2006-05-31]\n",
      "Second  column: [COMERCIAL] y date: [2006-06-30]\n",
      "Second  column: [COMERCIAL] y date: [2006-07-31]\n",
      "Second  column: [COMERCIAL] y date: [2006-08-31]\n",
      "Second  column: [COMERCIAL] y date: [2006-09-29]\n",
      "Second  column: [COMERCIAL] y date: [2006-10-31]\n",
      "Second  column: [COMERCIAL] y date: [2006-11-30]\n",
      "Second  column: [COMERCIAL] y date: [2006-12-29]\n",
      "Second  column: [COMERCIAL] y date: [2007-01-31]\n",
      "Second  column: [COMERCIAL] y date: [2007-02-28]\n",
      "Second  column: [COMERCIAL] y date: [2007-03-30]\n",
      "Second  column: [COMERCIAL] y date: [2007-04-30]\n",
      "Second  column: [COMERCIAL] y date: [2007-05-31]\n",
      "Second  column: [COMERCIAL] y date: [2007-06-28]\n",
      "Second  column: [COMERCIAL] y date: [2007-07-31]\n",
      "Second  column: [COMERCIAL] y date: [2007-08-31]\n",
      "Second  column: [COMERCIAL] y date: [2007-09-28]\n",
      "Second  column: [COMERCIAL] y date: [2007-10-31]\n",
      "Second  column: [COMERCIAL] y date: [2007-11-30]\n",
      "Second  column: [COMERCIAL] y date: [2007-12-31]\n",
      "Second  column: [COMERCIAL] y date: [2008-01-31]\n",
      "Second  column: [COMERCIAL] y date: [2008-02-29]\n",
      "Second  column: [COMERCIAL] y date: [2008-03-31]\n",
      "Second  column: [COMERCIAL] y date: [2008-04-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2008-05-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2008-06-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2008-07-31]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2008-08-29]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2008-09-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2008-10-31]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2008-11-28]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2008-12-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-01-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-02-27]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-03-31]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-04-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-05-29]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-06-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-07-31]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-08-31]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-09-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-10-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-11-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2009-12-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2010-01-29]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2010-02-26]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2010-03-31]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2010-04-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2010-05-31]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2010-06-30]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2010-07-27]\n",
      "Second  column: [CRÉDITOS COMERCIALES] y date: [2010-08-31]\n",
      "Second  column: [Continental] y date: [2010-09-30]\n",
      "Second  column: [Continental] y date: [2010-10-29]\n",
      "Second  column: [Continental] y date: [2010-11-30]\n",
      "Second  column: [Continental] y date: [2010-12-31]\n",
      "Second  column: [Continental] y date: [2011-01-31]\n",
      "Second  column: [Continental] y date: [2011-02-28]\n",
      "Second  column: [Continental] y date: [2011-03-31]\n",
      "Second  column: [Continental] y date: [2011-04-29]\n",
      "Second  column: [Continental] y date: [2011-05-31]\n",
      "Second  column: [Continental] y date: [2011-06-30]\n",
      "Second  column: [Continental] y date: [2011-07-27]\n",
      "Second  column: [Continental] y date: [2011-08-31]\n",
      "Second  column: [Continental] y date: [2011-09-30]\n",
      "Second  column: [Continental] y date: [2011-10-28]\n",
      "Second  column: [Continental] y date: [2011-11-30]\n",
      "Second  column: [Continental] y date: [2011-12-30]\n",
      "Second  column: [Continental] y date: [2012-01-31]\n",
      "Second  column: [Continental] y date: [2012-02-29]\n",
      "Second  column: [Continental] y date: [2012-03-30]\n",
      "Second  column: [Continental] y date: [2012-04-30]\n",
      "Second  column: [Continental] y date: [2012-05-31]\n",
      "Second  column: [Continental] y date: [2012-06-28]\n",
      "Second  column: [Continental] y date: [2012-07-31]\n",
      "Second  column: [Continental] y date: [2012-08-29]\n",
      "Second  column: [Continental] y date: [2012-09-28]\n",
      "Second  column: [Continental] y date: [2012-10-31]\n",
      "Second  column: [Continental] y date: [2012-11-30]\n",
      "Second  column: [Continental] y date: [2012-12-28]\n",
      "Second  column: [Continental] y date: [2013-01-31]\n",
      "Second  column: [Continental] y date: [2013-02-28]\n",
      "Second  column: [Continental] y date: [2013-03-27]\n",
      "Second  column: [Continental] y date: [2013-04-30]\n",
      "Second  column: [Continental] y date: [2013-05-31]\n",
      "Second  column: [Continental] y date: [2013-06-28]\n",
      "Second  column: [Continental] y date: [2013-07-31]\n",
      "Second  column: [Continental] y date: [2013-08-29]\n",
      "Second  column: [Continental] y date: [2013-09-30]\n",
      "Second  column: [Continental] y date: [2013-10-31]\n",
      "Second  column: [Continental] y date: [2013-11-29]\n",
      "Second  column: [Continental] y date: [2013-12-30]\n",
      "Second  column: [Continental] y date: [2014-01-31]\n",
      "Second  column: [Continental] y date: [2014-02-28]\n",
      "Second  column: [Continental] y date: [2014-03-31]\n",
      "Second  column: [Continental] y date: [2014-04-30]\n",
      "Second  column: [Continental] y date: [2014-05-30]\n",
      "Second  column: [Continental] y date: [2014-06-30]\n",
      "Second  column: [Continental] y date: [2014-07-31]\n",
      "Second  column: [Continental] y date: [2014-08-29]\n",
      "Second  column: [Continental] y date: [2014-09-30]\n",
      "Second  column: [Continental] y date: [2014-10-31]\n",
      "Second  column: [Continental] y date: [2014-11-28]\n",
      "Second  column: [Continental] y date: [2014-12-31]\n",
      "Second  column: [Continental] y date: [2015-01-30]\n",
      "Second  column: [Continental] y date: [2015-02-27]\n",
      "Second  column: [Continental] y date: [2015-03-31]\n",
      "Second  column: [Continental] y date: [2015-04-30]\n",
      "Second  column: [Continental] y date: [2015-05-29]\n",
      "Second  column: [Continental] y date: [2015-06-30]\n",
      "Second  column: [Continental] y date: [2015-07-31]\n",
      "Second  column: [Continental] y date: [2015-08-31]\n",
      "Second  column: [Continental] y date: [2015-09-30]\n",
      "Second  column: [Continental] y date: [2015-10-30]\n",
      "Second  column: [Continental] y date: [2015-11-30]\n",
      "Second  column: [Continental] y date: [2015-12-31]\n",
      "Second  column: [Continental] y date: [2016-01-29]\n",
      "Second  column: [Continental] y date: [2016-02-29]\n",
      "Second  column: [Continental] y date: [2016-03-31]\n",
      "Second  column: [Continental] y date: [2016-04-29]\n",
      "Second  column: [Continental] y date: [2016-05-31]\n",
      "Second  column: [Continental] y date: [2016-06-30]\n",
      "Second  column: [Continental] y date: [2016-07-27]\n",
      "Second  column: [Continental] y date: [2016-08-31]\n",
      "Second  column: [Continental] y date: [2016-09-30]\n",
      "Second  column: [Continental] y date: [2016-10-31]\n",
      "Second  column: [Continental] y date: [2016-11-30]\n",
      "Second  column: [Continental] y date: [2016-12-30]\n",
      "Second  column: [Continental] y date: [2017-01-31]\n",
      "Second  column: [Continental] y date: [2017-02-28]\n",
      "Second  column: [Continental] y date: [2017-03-31]\n",
      "Second  column: [Continental] y date: [2017-04-28]\n",
      "Second  column: [Continental] y date: [2017-05-31]\n",
      "Second  column: [Continental] y date: [2017-06-28]\n",
      "Second  column: [Continental] y date: [2017-07-31]\n",
      "Second  column: [Continental] y date: [2017-08-31]\n",
      "Second  column: [Continental] y date: [2017-09-29]\n",
      "Second  column: [Continental] y date: [2017-10-31]\n",
      "Second  column: [Continental] y date: [2017-11-30]\n",
      "Second  column: [Continental] y date: [2017-12-29]\n",
      "Second  column: [Continental] y date: [2018-01-31]\n",
      "Second  column: [Continental] y date: [2018-02-28]\n",
      "Second  column: [Continental] y date: [2018-03-28]\n",
      "Second  column: [Continental] y date: [2018-04-30]\n",
      "Second  column: [Continental] y date: [2018-05-31]\n",
      "Second  column: [Continental] y date: [2018-06-28]\n",
      "Second  column: [Continental] y date: [2018-07-31]\n",
      "Second  column: [Continental] y date: [2018-08-29]\n",
      "Second  column: [Continental] y date: [2018-09-28]\n",
      "Second  column: [Continental] y date: [2018-10-31]\n",
      "Second  column: [Continental] y date: [2018-11-30]\n",
      "Second  column: [Continental] y date: [2018-12-31]\n",
      "Second  column: [Continental] y date: [2019-01-31]\n",
      "Second  column: [Continental] y date: [2019-02-28]\n",
      "Second  column: [Continental] y date: [2019-03-28]\n",
      "Second  column: [Continental] y date: [2019-04-30]\n",
      "Second  column: [Continental] y date: [2019-05-31]\n",
      "Second  column: [BBVA] y date: [2019-06-28]\n",
      "Second  column: [BBVA] y date: [2019-07-31]\n",
      "Second  column: [BBVA] y date: [2019-08-27]\n",
      "Second  column: [BBVA] y date: [2019-09-30]\n",
      "Second  column: [BBVA] y date: [2019-10-30]\n",
      "Second  column: [BBVA] y date: [2019-11-29]\n",
      "Second  column: [BBVA] y date: [2019-12-31]\n",
      "Second  column: [BBVA] y date: [2020-01-31]\n",
      "Second  column: [BBVA] y date: [2020-02-28]\n",
      "Second  column: [BBVA] y date: [2020-03-31]\n",
      "Second  column: [BBVA] y date: [2020-04-30]\n",
      "Second  column: [BBVA] y date: [2020-05-29]\n",
      "Second  column: [BBVA] y date: [2020-06-30]\n",
      "Second  column: [BBVA] y date: [2020-07-31]\n",
      "Second  column: [BBVA] y date: [2020-08-31]\n",
      "Second  column: [BBVA] y date: [2020-09-30]\n",
      "Second  column: [BBVA] y date: [2020-10-30]\n",
      "Second  column: [BBVA] y date: [2020-11-30]\n",
      "Second  column: [BBVA] y date: [2020-12-31]\n",
      "Second  column: [BBVA] y date: [2021-01-29]\n",
      "Second  column: [BBVA] y date: [2021-02-26]\n",
      "Second  column: [BBVA] y date: [2021-03-31]\n",
      "Second  column: [BBVA] y date: [2021-04-30]\n",
      "Second  column: [BBVA] y date: [2021-05-31]\n",
      "Second  column: [BBVA] y date: [2021-06-30]\n",
      "Second  column: [BBVA] y date: [2021-07-30]\n",
      "Second  column: [BBVA] y date: [2021-08-31]\n",
      "Second  column: [BBVA] y date: [2021-09-30]\n",
      "Second  column: [BBVA] y date: [2021-10-29]\n",
      "Second  column: [BBVA] y date: [2021-11-30]\n",
      "Second  column: [BBVA] y date: [2021-12-31]\n",
      "Second  column: [BBVA] y date: [2022-01-31]\n",
      "Second  column: [BBVA] y date: [2022-02-28]\n",
      "Second  column: [BBVA] y date: [2022-03-31]\n",
      "Second  column: [BBVA] y date: [2022-04-29]\n",
      "Second  column: [BBVA] y date: [2022-05-31]\n",
      "Second  column: [BBVA] y date: [2022-06-30]\n",
      "Second  column: [BBVA] y date: [2022-07-27]\n",
      "Second  column: [BBVA] y date: [2022-08-31]\n"
     ]
    }
   ],
   "source": [
    "# Identification of the different structures in the dataframes\n",
    "df = pd.DataFrame(columns = [\"SegundaColumna\", \"Fecha\"])\n",
    "i = 0\n",
    "\n",
    "for x in xlsx_files:\n",
    "    df.loc[i,\"SegundaColumna\"] = d[\"table_\"+x].columns[1]\n",
    "    df.loc[i,\"Fecha\"] = d[\"table_\"+x].iloc[0,-1]\n",
    "    i += 1\n",
    "\n",
    "df = df.sort_values(\"Fecha\").reset_index()\n",
    "\n",
    "for x in range(np.shape(df)[0]):\n",
    "    print(f'Second  column: [{df.loc[x,\"SegundaColumna\"]}] y date: [{df.loc[x,\"Fecha\"]}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogenize all the dataframes:\n",
    "for x in xlsx_files:\n",
    "    if datetime.strptime(\"30_5_2008\", \"%d_%m_%Y\").date() > datetime.strptime(x, \"%d_%m_%Y\").date() > datetime.strptime(\"31_3_2001\", \"%d_%m_%Y\").date():\n",
    "        d[\"table_\"+x].columns = ['Tasa Anual (%)']+list(d[\"table_\"+x].iloc[1])[1:]\n",
    "        d[\"table_\"+x] = d[\"table_\"+x].loc[2:,:]\n",
    "        d[\"table_\"+x] = d[\"table_\"+x].transpose().reset_index()\n",
    "        d[\"table_\"+x].columns = list(d[\"table_\"+x].iloc[0])\n",
    "        d[\"table_\"+x] = d[\"table_\"+x].iloc[1:-1,:]\n",
    "        d[\"table_\"+x][\"date_info\"] = datetime.strptime(x, \"%d_%m_%Y\").date()\n",
    "        d[\"table_\"+x].columns = [*map(lambda k: re.sub(\"BANCO DE |BANCO | BANCO| DEL PERU| BANK PERU| PERU|\\(\\*\\)\",\"\",str(k)), d[\"table_\"+x].columns)]\n",
    "        d[\"table_\"+x].rename(columns = {\"Promedio del Sistema\": \"Promedio\", \"BANBIF\": \"BIF\", \"B SANTANDER CENTRAL\": \"SANTANDER\"}, inplace = True)\n",
    "        d[\"table_\"+x].rename(columns = {\"FINANCIERO\": \"PICHINCHA\", \"AZTECA\": \"ALFIN\"}, inplace = True)\n",
    "    elif datetime.strptime(\"30_9_2010\", \"%d_%m_%Y\").date() > datetime.strptime(x, \"%d_%m_%Y\").date() > datetime.strptime(\"30_4_2008\", \"%d_%m_%Y\").date():\n",
    "        d[\"table_\"+x].columns = ['Tasa Anual (%)']+list(d[\"table_\"+x].iloc[1])[1:]\n",
    "        d[\"table_\"+x] = d[\"table_\"+x].loc[2:,:]\n",
    "        d[\"table_\"+x] = d[\"table_\"+x].transpose().reset_index()\n",
    "        d[\"table_\"+x].columns = list(d[\"table_\"+x].iloc[0])\n",
    "        d[\"table_\"+x] = d[\"table_\"+x].iloc[1:-1,:]\n",
    "        pos = list(d[\"table_\"+x].iloc[:,1]).index(\"Tarjetas de Crédito\")\n",
    "        d[\"table_\"+x].iloc[pos:,1:-1] = d[\"table_\"+x].iloc[pos:,2:]\n",
    "        d[\"table_\"+x][\"date_info\"] = datetime.strptime(x, \"%d_%m_%Y\").date()\n",
    "        d[\"table_\"+x].columns = [*map(lambda k: re.sub(\"BANCO DE |BANCO | BANCO| DEL PERU| BANK PERU| PERU|\\(\\*\\)\",\"\",str(k)), d[\"table_\"+x].columns)]\n",
    "        d[\"table_\"+x].rename(columns = {\"Promedio del Sistema\": \"Promedio\", \"BANBIF\": \"BIF\", \"B SANTANDER CENTRAL\": \"SANTANDER\"}, inplace = True)\n",
    "        d[\"table_\"+x].rename(columns = {\"FINANCIERO\": \"PICHINCHA\", \"AZTECA\": \"ALFIN\"}, inplace = True)\n",
    "    else:\n",
    "        d[\"table_\"+x].columns = [d[\"table_\"+x].columns[0]]+[*map(lambda k: k.upper(), d[\"table_\"+x].columns[1:-2])]+d[\"table_\"+x].columns[-2:].tolist()\n",
    "        d[\"table_\"+x].rename(columns = {\"CRÉDITO\": \"CREDITO\",\"CONTINENTAL\": \"BBVA\", \"BANCO GNB\": \"GNB\"}, inplace = True)\n",
    "        d[\"table_\"+x].columns = [*map(lambda k: re.sub(\"  \\*\",\"\",str(k)), d[\"table_\"+x].columns)]\n",
    "        d[\"table_\"+x].rename(columns = {\"FINANCIERO\": \"PICHINCHA\", \"AZTECA\": \"ALFIN\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the dataframes in a bigger dataframe\n",
    "data_rates = d[\"table_\"+xlsx_files[0]].copy()\n",
    "data_rates = data_rates[list(data_rates.columns[[0,-1]])+list(data_rates.columns[1:-1])]\n",
    "\n",
    "for x in xlsx_files[1:]:\n",
    "    data_rates = pd.concat([data_rates,d[\"table_\"+x]])\n",
    "    \n",
    "data_rates = data_rates[[*map(lambda k: not bool(re.search(\"^Nota\", str(k))), data_rates[\"Tasa Anual (%)\"])]]\n",
    "data_rates.drop(\"nan\", axis = \"columns\", inplace = True)\n",
    "\n",
    "for x in list(data_rates.columns)[2:]:\n",
    "    data_rates.loc[data_rates[x] == '-', x] = np.nan\n",
    "    data_rates.loc[data_rates[x] == 's.i.', x] = np.nan\n",
    "    data_rates[x] = pd.to_numeric(data_rates[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tasa Anual (%)</th>\n",
       "      <th>date_info</th>\n",
       "      <th>TRABAJO</th>\n",
       "      <th>BBVA</th>\n",
       "      <th>COMERCIO</th>\n",
       "      <th>CREDITO</th>\n",
       "      <th>PICHINCHA</th>\n",
       "      <th>BIF</th>\n",
       "      <th>STANDARD CHARTERED</th>\n",
       "      <th>SUDAMERICANO</th>\n",
       "      <th>...</th>\n",
       "      <th>SANTANDER</th>\n",
       "      <th>RIPLEY</th>\n",
       "      <th>ALFIN</th>\n",
       "      <th>DEUTSCHE</th>\n",
       "      <th>GNB</th>\n",
       "      <th>ICBC</th>\n",
       "      <th>BANK OF CHINA</th>\n",
       "      <th>CENCOSUD</th>\n",
       "      <th>CAT</th>\n",
       "      <th>BCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avances en Cta.Corriente</td>\n",
       "      <td>2004-02-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.73</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sobregiros</td>\n",
       "      <td>2004-02-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.79</td>\n",
       "      <td>138.18</td>\n",
       "      <td>89.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.30</td>\n",
       "      <td>25.0</td>\n",
       "      <td>58.10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dsctos. y préstamos hasta 30 días</td>\n",
       "      <td>2004-02-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.19</td>\n",
       "      <td>47.46</td>\n",
       "      <td>4.62</td>\n",
       "      <td>15.87</td>\n",
       "      <td>14.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.68</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dsctos. y préstamos 31 - 90 días</td>\n",
       "      <td>2004-02-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.94</td>\n",
       "      <td>21.61</td>\n",
       "      <td>7.19</td>\n",
       "      <td>15.71</td>\n",
       "      <td>10.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.90</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dsctos. y préstamos 91 - 180 días</td>\n",
       "      <td>2004-02-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>19.71</td>\n",
       "      <td>5.34</td>\n",
       "      <td>15.82</td>\n",
       "      <td>10.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.98</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Préstamos no Revolventes para libre disponibil...</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.13</td>\n",
       "      <td>33.35</td>\n",
       "      <td>63.03</td>\n",
       "      <td>26.69</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.93</td>\n",
       "      <td>74.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Préstamos no Revolventes para libre disponibil...</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.22</td>\n",
       "      <td>14.66</td>\n",
       "      <td>18.99</td>\n",
       "      <td>33.05</td>\n",
       "      <td>13.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.03</td>\n",
       "      <td>69.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Créditos pignoraticios</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Hipotecarios</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.28</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.27</td>\n",
       "      <td>8.72</td>\n",
       "      <td>9.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Préstamos hipotecarios para vivienda</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.28</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.27</td>\n",
       "      <td>8.72</td>\n",
       "      <td>9.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9028 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Tasa Anual (%)   date_info  TRABAJO  \\\n",
       "1                            Avances en Cta.Corriente  2004-02-26      NaN   \n",
       "2                                          Sobregiros  2004-02-26      NaN   \n",
       "3                   Dsctos. y préstamos hasta 30 días  2004-02-26      NaN   \n",
       "4                    Dsctos. y préstamos 31 - 90 días  2004-02-26      NaN   \n",
       "5                   Dsctos. y préstamos 91 - 180 días  2004-02-26      NaN   \n",
       "..                                                ...         ...      ...   \n",
       "41  Préstamos no Revolventes para libre disponibil...  2022-08-31      NaN   \n",
       "42  Préstamos no Revolventes para libre disponibil...  2022-08-31      NaN   \n",
       "43                             Créditos pignoraticios  2022-08-31      NaN   \n",
       "44                                       Hipotecarios  2022-08-31      NaN   \n",
       "45               Préstamos hipotecarios para vivienda  2022-08-31      NaN   \n",
       "\n",
       "     BBVA  COMERCIO  CREDITO  PICHINCHA    BIF  STANDARD CHARTERED  \\\n",
       "1   38.92       NaN    73.34        NaN  39.08                 NaN   \n",
       "2   48.79    138.18    89.00        NaN  68.30                25.0   \n",
       "3    8.19     47.46     4.62      15.87  14.43                 NaN   \n",
       "4    5.94     21.61     7.19      15.71  10.91                 NaN   \n",
       "5   10.00     19.71     5.34      15.82  10.71                 NaN   \n",
       "..    ...       ...      ...        ...    ...                 ...   \n",
       "41  22.13     33.35    63.03      26.69  10.00                 NaN   \n",
       "42  18.22     14.66    18.99      33.05  13.39                 NaN   \n",
       "43    NaN     42.40      NaN        NaN    NaN                 NaN   \n",
       "44   9.28      9.08     9.27       8.72   9.23                 NaN   \n",
       "45   9.28      9.08     9.27       8.72   9.23                 NaN   \n",
       "\n",
       "    SUDAMERICANO  ...  SANTANDER  RIPLEY  ALFIN  DEUTSCHE    GNB  ICBC  \\\n",
       "1          31.73  ...        NaN     NaN    NaN       NaN    NaN   NaN   \n",
       "2          58.10  ...        NaN     NaN    NaN       NaN    NaN   NaN   \n",
       "3          30.68  ...        NaN     NaN    NaN       NaN    NaN   NaN   \n",
       "4          11.90  ...        NaN     NaN    NaN       NaN    NaN   NaN   \n",
       "5           9.98  ...        NaN     NaN    NaN       NaN    NaN   NaN   \n",
       "..           ...  ...        ...     ...    ...       ...    ...   ...   \n",
       "41           NaN  ...        NaN   39.93  74.42       NaN    NaN   NaN   \n",
       "42           NaN  ...        NaN   26.03  69.00       NaN  11.30   NaN   \n",
       "43           NaN  ...        NaN     NaN    NaN       NaN    NaN   NaN   \n",
       "44           NaN  ...        NaN     NaN    NaN       NaN   8.03   NaN   \n",
       "45           NaN  ...        NaN     NaN    NaN       NaN   8.03   NaN   \n",
       "\n",
       "    BANK OF CHINA  CENCOSUD  CAT  BCI  \n",
       "1             NaN       NaN  NaN  NaN  \n",
       "2             NaN       NaN  NaN  NaN  \n",
       "3             NaN       NaN  NaN  NaN  \n",
       "4             NaN       NaN  NaN  NaN  \n",
       "5             NaN       NaN  NaN  NaN  \n",
       "..            ...       ...  ...  ...  \n",
       "41            NaN       NaN  NaN  NaN  \n",
       "42            NaN       NaN  NaN  NaN  \n",
       "43            NaN       NaN  NaN  NaN  \n",
       "44            NaN       NaN  NaN  NaN  \n",
       "45            NaN       NaN  NaN  NaN  \n",
       "\n",
       "[9028 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 3:\n",
    "First, we replace some names of rates that refer to credit cards so we have all of them by the name `Tarjetas de Crédito`. <br>\n",
    "Then, we create the column `year` by formating the column `date_info` using the `strftime` method and selecting just the year. <br>\n",
    "Finally, we create the new dataframe with the information of the 5 biggest rates for year and kind of rate (only for the two indicated). The steps followed are the following:\n",
    "1. Make a new dataframe only considering the rates `Préstamos hipotecarios para vivienda` and `Tarjetas de Crédito`.\n",
    "2. Drop the columns `date_info` and `Promedio`.\n",
    "3. Using the `melt` function we convert all the column names that refer to banks into a single column called `variables` and the corresponding rates in a column named `values`.\n",
    "4. We change all the column names so the new dataframe adjust to the indicated.\n",
    "5. We get information only for the five top rates per year and type of rate. For this, we sort the values in a descending way by `rate_value` column. Then, we group the data by `year` and `rate_concept`. One we have that we select just the first 5 observations for each group and use the `rese_index`. Finally, we sort the new dataframe by `year`, `rate_concept` and `rate_value` in ascending way the first two and in descending way the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rates[\"Tasa Anual (%)\"] = data_rates[\"Tasa Anual (%)\"].replace([\"Tarjetas de crédito abiertas4\", \"Tarjetas de crédito cerradas5\", \"Tarjetas de crédito\", \"Tarjetas de Crdito\"], \"Tarjetas de Crédito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rates[\"year\"] = [*map(lambda x: x.strftime(\"%Y\"), data_rates[\"date_info\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rate_concept</th>\n",
       "      <th>banks</th>\n",
       "      <th>rate_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2001</td>\n",
       "      <td>Préstamos hipotecarios para vivienda</td>\n",
       "      <td>MIBANCO</td>\n",
       "      <td>14.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2001</td>\n",
       "      <td>Préstamos hipotecarios para vivienda</td>\n",
       "      <td>COMERCIO</td>\n",
       "      <td>8.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2001</td>\n",
       "      <td>Préstamos hipotecarios para vivienda</td>\n",
       "      <td>PICHINCHA</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2001</td>\n",
       "      <td>Préstamos hipotecarios para vivienda</td>\n",
       "      <td>GNB</td>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2001</td>\n",
       "      <td>Préstamos hipotecarios para vivienda</td>\n",
       "      <td>BIF</td>\n",
       "      <td>6.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2022</td>\n",
       "      <td>Tarjetas de Crédito</td>\n",
       "      <td>FALABELLA</td>\n",
       "      <td>79.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2022</td>\n",
       "      <td>Tarjetas de Crédito</td>\n",
       "      <td>FALABELLA</td>\n",
       "      <td>79.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2022</td>\n",
       "      <td>Tarjetas de Crédito</td>\n",
       "      <td>FALABELLA</td>\n",
       "      <td>79.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2022</td>\n",
       "      <td>Tarjetas de Crédito</td>\n",
       "      <td>FALABELLA</td>\n",
       "      <td>78.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2022</td>\n",
       "      <td>Tarjetas de Crédito</td>\n",
       "      <td>FALABELLA</td>\n",
       "      <td>78.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year                          rate_concept      banks  rate_value\n",
       "169  2001  Préstamos hipotecarios para vivienda    MIBANCO       14.25\n",
       "176  2001  Préstamos hipotecarios para vivienda   COMERCIO        8.24\n",
       "177  2001  Préstamos hipotecarios para vivienda  PICHINCHA        8.20\n",
       "178  2001  Préstamos hipotecarios para vivienda        GNB        7.69\n",
       "179  2001  Préstamos hipotecarios para vivienda        BIF        6.88\n",
       "..    ...                                   ...        ...         ...\n",
       "93   2022                   Tarjetas de Crédito  FALABELLA       79.81\n",
       "95   2022                   Tarjetas de Crédito  FALABELLA       79.16\n",
       "96   2022                   Tarjetas de Crédito  FALABELLA       79.03\n",
       "97   2022                   Tarjetas de Crédito  FALABELLA       78.89\n",
       "98   2022                   Tarjetas de Crédito  FALABELLA       78.44\n",
       "\n",
       "[180 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5 = data_rates.copy().loc[data_rates[\"Tasa Anual (%)\"].isin([\"Préstamos hipotecarios para vivienda\",\"Tarjetas de Crédito\"])]\n",
    "top5.drop([\"date_info\", \"Promedio\"], axis = \"columns\", inplace = True)\n",
    "top5 = top5.melt(id_vars = [\"year\", \"Tasa Anual (%)\"])\n",
    "top5.columns = [\"year\", \"rate_concept\", \"banks\", \"rate_value\"]\n",
    "top5 = top5.sort_values(\"rate_value\", ascending = False).groupby([\"year\",\"rate_concept\"]).head(5).reset_index(drop = True).sort_values([\"year\",\"rate_concept\",\"rate_value\"], ascending = [True, True, False])\n",
    "top5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 4:\n",
    "First we create the path required. We use three `if` statements, one for each new folder. Using `os.path.exists` function, each `if` statement evaluates if the current folder already exist, if not, it creates the folder using the `os.makedirs` function. <br>\n",
    "Once we assure that the path exists, we use a `for loop` export a fraction of the dataframe that contains information for each bank. We get the names of all the banks in the list by using the `unique` method over the values in `banks` column. The name of each new databe is going to be \"table_\" plus the name of the bank in lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "if not os.path.exists(\"output/sbs\"):\n",
    "    os.makedirs(\"output/sbs\")\n",
    "if not os.path.exists(\"output/sbs/group4\"):\n",
    "    os.makedirs(\"output/sbs/group4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in top5.banks.unique().tolist():\n",
    "    top5.loc[top5[\"banks\"] == x,:].to_excel(\"output/sbs/group4/table_\"+x.lower()+\".xlsx\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
