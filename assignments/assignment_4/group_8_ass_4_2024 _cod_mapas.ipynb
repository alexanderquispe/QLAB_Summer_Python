{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }a\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Hp\\\\Documents\\\\GitHub\\\\QLAB_Summer_Python\\\\_data\\\\8_trab_sex_20.dta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Get data of labor\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m sex_work \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_stata( \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mQLAB_Summer_Python\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m8_trab_sex_20.dta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m sex_work[ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdpt_code\u001b[39m\u001b[38;5;124m'\u001b[39m ] \u001b[38;5;241m=\u001b[39m sex_work\u001b[38;5;241m.\u001b[39mcod_ubigeo\u001b[38;5;241m.\u001b[39mstr[ :\u001b[38;5;241m2\u001b[39m ]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     20\u001b[0m sex_work[ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprov_code\u001b[39m\u001b[38;5;124m'\u001b[39m ] \u001b[38;5;241m=\u001b[39m sex_work\u001b[38;5;241m.\u001b[39mcod_ubigeo\u001b[38;5;241m.\u001b[39mstr[ :\u001b[38;5;241m4\u001b[39m ]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:2090\u001b[0m, in \u001b[0;36mread_stata\u001b[1;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, compression, storage_options)\u001b[0m\n\u001b[0;32m   2087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\n\u001b[0;32m   2089\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[1;32m-> 2090\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1702\u001b[0m, in \u001b[0;36mStataReader.read\u001b[1;34m(self, nrows, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals)\u001b[0m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_read_method_doc)\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[0;32m   1692\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1700\u001b[0m     order_categoricals: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1701\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 1702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_open()\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# Handle empty file or chunk.  If reading incrementally raise\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m     \u001b[38;5;66;03m# StopIteration.  If reading the whole thing return an empty\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     \u001b[38;5;66;03m# data frame.\u001b[39;00m\n\u001b[0;32m   1706\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (nrows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1176\u001b[0m, in \u001b[0;36mStataReader._ensure_open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;124;03mEnsure the file has been opened and its header data read.\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_path_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_file()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1189\u001b[0m, in \u001b[0;36mStataReader._open_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entered:\n\u001b[0;32m   1183\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStataReader is being used without using a context manager. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing StataReader as a context manager is the only supported method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1186\u001b[0m         \u001b[38;5;167;01mResourceWarning\u001b[39;00m,\n\u001b[0;32m   1187\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1188\u001b[0m     )\n\u001b[1;32m-> 1189\u001b[0m handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_path_or_buf,\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1192\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_options,\n\u001b[0;32m   1193\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1194\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression,\n\u001b[0;32m   1195\u001b[0m )\n\u001b[0;32m   1196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;66;03m# If the handle is directly seekable, use it without an extra copy.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_or_buf \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Hp\\\\Documents\\\\GitHub\\\\QLAB_Summer_Python\\\\_data\\\\8_trab_sex_20.dta'"
     ]
    }
   ],
   "source": [
    "## MAP 1\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }a\n",
    "</style>\n",
    "\"\"\"))\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Get data of labor\n",
    "sex_work = pd.read_stata( r'C:\\Users\\Hp\\Documents\\GitHub\\QLAB_Summer_Python\\_data\\8_trab_sex_20.dta')\n",
    "sex_work[ 'dpt_code' ] = sex_work.cod_ubigeo.str[ :2 ].copy()\n",
    "sex_work[ 'prov_code' ] = sex_work.cod_ubigeo.str[ :4 ].copy()\n",
    "\n",
    "# Sex work\n",
    "women_work = sex_work[ sex_work.sex == 'Mujer' ].copy().reset_index( drop = True )\n",
    "\n",
    "# get data from lima\n",
    "women_work[ 'month' ] = pd.to_datetime( women_work.month , format = '%B' ) \\\n",
    "                                    .dt.strftime( '%m' ) \\\n",
    "                                    .astype( int )\n",
    "\n",
    "# Sort by department and month\n",
    "women_work.sort_values([ 'dpt_code', 'month'], inplace = True )\n",
    "\n",
    "# Get the total number of women workers by dpt\n",
    "dpt_women_work = women_work.groupby( [ 'dpt_code', 'month'], as_index = False )[['empl']] \\\n",
    "                            .sum() \\\n",
    "                            .rename( columns = {'empl' :'women_empl'})\n",
    "\n",
    "# Sort by dpt code and month\n",
    "dpt_women_work.sort_values([ 'dpt_code', 'month'], inplace = True )\n",
    "\n",
    "df2 = dpt_women_work.groupby( ['dpt_code'],as_index = False )[['women_empl']].mean()\n",
    "\n",
    "#SHAPEFILE:\n",
    "dpt_shp = gpd.read_file( r'C:\\Users\\Hp\\Documents\\GitHub\\QLAB_Summer_Python\\_data\\INEI_LIMITE_DEPARTAMENTAL\\INEI_LIMITE_DEPARTAMENTAL.shp' )\n",
    "df3 = dpt_shp.merge( df2, left_on = 'CCDD', right_on = 'dpt_code'  )\n",
    "df3.plot( column='women_empl', cmap='Reds', figsize=(20, 20), linestyle='--',\n",
    "                      edgecolor='black', \n",
    "                      legend = True)\n",
    "\n",
    "\n",
    "import folium\n",
    "from folium import Choropleth\n",
    "\n",
    "# Convert GeoDataFrame to GeoJSON\n",
    "df3_geojson = df3[['dpt_code', 'women_empl', 'geometry']].to_json()\n",
    "\n",
    "# Create a Map instance\n",
    "m = folium.Map(location=[-9.1900, -75.0152], zoom_start=6)  # Coordinates for Peru\n",
    "\n",
    "# Create a Choropleth layer and add it to the map\n",
    "Choropleth(\n",
    "    geo_data=df3_geojson,\n",
    "    name='choropleth',\n",
    "    data=df3,\n",
    "    columns=['dpt_code', 'women_empl'],\n",
    "    key_on='feature.properties.dpt_code',\n",
    "    fill_color='Reds',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Number of Employers',\n",
    "    \n",
    ").add_to(m)\n",
    "\n",
    "from folium import IFrame\n",
    "\n",
    "# Create an IFrame to embed the map\n",
    "iframe = IFrame(\"folium_map.html\", width=900, height=600)\n",
    "\n",
    "# Display the map in the notebook\n",
    "display(folium.Map(location=[-9.1900, -75.0152], zoom_start=6).add_child(folium.Marker(location=[-9.1900, -75.0152], popup=folium.Popup(iframe))))\n",
    "\n",
    "classification_kwds=dict(bins=[20000, 40000, 60000, 100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP 2\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "df3.plot( ax = ax, \n",
    "        column='women_empl', \n",
    "         cmap= 'Reds', \n",
    "         figsize=(20, 20), \n",
    "         linestyle='--',\n",
    "         edgecolor='black', \n",
    "         legend = True,  \n",
    "         scheme = \"User_Defined\", \n",
    "         classification_kwds = dict( bins = [ 20000, 40000, 60000, 100000  ] ), \n",
    "         legend_kwds = dict(  loc='upper left',\n",
    "                            bbox_to_anchor=(1.01, 1),\n",
    "                            fontsize='x-large',\n",
    "                            title= \"Number of Employers\", \n",
    "                            title_fontsize = 'x-large', \n",
    "                            frameon= False )\n",
    "        )\n",
    "\n",
    "import folium\n",
    "from folium import Choropleth\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Convert GeoDataFrame to GeoJSON\n",
    "df3_geojson = df3[['dpt_code', 'women_empl', 'geometry']].to_json()\n",
    "\n",
    "# Create a Map instance\n",
    "m = folium.Map(location=[-9.1900, -75.0152], zoom_start=6)  # Coordinates for Peru\n",
    "\n",
    "# Create a Choropleth layer and add it to the map\n",
    "Choropleth(\n",
    "    geo_data=df3_geojson,\n",
    "    name='choropleth',\n",
    "    data=df3,\n",
    "    columns=['dpt_code', 'women_empl'],\n",
    "    key_on='feature.properties.dpt_code',\n",
    "    fill_color='Reds',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Number of Employers',\n",
    "    bins=[20000, 40000, 60000, 100000]\n",
    ").add_to(m)\n",
    "\n",
    "# Create a MarkerCluster layer for additional information if needed\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Add markers or other information to the MarkerCluster layer\n",
    "# For example, add a popup for each department with the number of employers\n",
    "for idx, row in df3.iterrows():\n",
    "    popup_text = f\"Department: {row['dpt_code']}<br>Employers: {row['women_empl']}\"\n",
    "    folium.Marker([row['geometry'].centroid.y, row['geometry'].centroid.x], popup=popup_text).add_to(marker_cluster)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "m.save(\"folium_map.html\")\n",
    "\n",
    "# Display the map in the notebook\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }a\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Hp\\\\Documents\\\\GitHub\\\\QLAB_Summer_Python\\\\_data\\\\8_trab_sex_20.dta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Get data of labor\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m sex_work \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_stata( \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mQLAB_Summer_Python\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m8_trab_sex_20.dta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m sex_work[ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdpt_code\u001b[39m\u001b[38;5;124m'\u001b[39m ] \u001b[38;5;241m=\u001b[39m sex_work\u001b[38;5;241m.\u001b[39mcod_ubigeo\u001b[38;5;241m.\u001b[39mstr[ :\u001b[38;5;241m2\u001b[39m ]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     21\u001b[0m sex_work[ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprov_code\u001b[39m\u001b[38;5;124m'\u001b[39m ] \u001b[38;5;241m=\u001b[39m sex_work\u001b[38;5;241m.\u001b[39mcod_ubigeo\u001b[38;5;241m.\u001b[39mstr[ :\u001b[38;5;241m4\u001b[39m ]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:2090\u001b[0m, in \u001b[0;36mread_stata\u001b[1;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, compression, storage_options)\u001b[0m\n\u001b[0;32m   2087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\n\u001b[0;32m   2089\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[1;32m-> 2090\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1702\u001b[0m, in \u001b[0;36mStataReader.read\u001b[1;34m(self, nrows, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals)\u001b[0m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_read_method_doc)\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[0;32m   1692\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1700\u001b[0m     order_categoricals: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1701\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 1702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_open()\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# Handle empty file or chunk.  If reading incrementally raise\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m     \u001b[38;5;66;03m# StopIteration.  If reading the whole thing return an empty\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     \u001b[38;5;66;03m# data frame.\u001b[39;00m\n\u001b[0;32m   1706\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (nrows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1176\u001b[0m, in \u001b[0;36mStataReader._ensure_open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;124;03mEnsure the file has been opened and its header data read.\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_path_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_file()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1189\u001b[0m, in \u001b[0;36mStataReader._open_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entered:\n\u001b[0;32m   1183\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStataReader is being used without using a context manager. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing StataReader as a context manager is the only supported method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1186\u001b[0m         \u001b[38;5;167;01mResourceWarning\u001b[39;00m,\n\u001b[0;32m   1187\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1188\u001b[0m     )\n\u001b[1;32m-> 1189\u001b[0m handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_path_or_buf,\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1192\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_options,\n\u001b[0;32m   1193\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1194\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression,\n\u001b[0;32m   1195\u001b[0m )\n\u001b[0;32m   1196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;66;03m# If the handle is directly seekable, use it without an extra copy.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_or_buf \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Hp\\\\Documents\\\\GitHub\\\\QLAB_Summer_Python\\\\_data\\\\8_trab_sex_20.dta'"
     ]
    }
   ],
   "source": [
    "# MAP 3\n",
    "\n",
    "import folium\n",
    "from folium import Choropleth\n",
    "\n",
    "df3_filtered = df3[df3['dpt_code'] != '15']\n",
    "\n",
    "# Convert the filtered GeoDataFrame to GeoJSON\n",
    "df3_geojson = df3_filtered[['dpt_code', 'women_empl', 'geometry']].to_json()\n",
    "\n",
    "# Create a Map instance\n",
    "map_3 = folium.Map(location=[-9.1900, -75.0152], zoom_start=6)  # Coordinates for Peru\n",
    "\n",
    "# Create a Choropleth layer and add it to the map\n",
    "Choropleth(\n",
    "    geo_data=df3_geojson,\n",
    "    name='choropleth',\n",
    "    data=df3,\n",
    "    columns=['dpt_code', 'women_empl'],\n",
    "    key_on='feature.properties.dpt_code',\n",
    "    fill_color='Reds',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Number of Employers',\n",
    ").add_to(map_3)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "map_3.save(\"folium_map.html\")\n",
    "\n",
    "map_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##MAP 6\n",
    "df4 = sex_work.groupby( ['dpt_code', 'month', 'sex'], as_index = False )[['empl']].sum() \\\n",
    "        .pivot( index = [ 'dpt_code', 'month' ] , columns = 'sex',values='empl') \\\n",
    "        .reset_index()\n",
    "df4[ 'prop_wom' ] = ( df4.Mujer * 100 / df4.Hombre )\n",
    "df5 = dpt_shp.merge( df4, left_on = 'CCDD', right_on = 'dpt_code'  )\n",
    "idx = 0\n",
    "month = df5.month.unique()[ idx ]\n",
    "df6 = df5[ df5.month == month ]\n",
    "df6.loc[ (df6.NOMBDEP == 'LIMA'), 'prop_wom' ] = np.nan\n",
    "\n",
    "df6_geojson = df6[['dpt_code', 'prop_wom', 'geometry']].to_json()\n",
    "\n",
    "# Create a Map instance\n",
    "map_6 = folium.Map(location=[-9.1900, -75.0152], zoom_start=6)  # Coordinates for Peru\n",
    "\n",
    "# Create a Choropleth layer and add it to the map\n",
    "Choropleth(\n",
    "    geo_data=df6_geojson,\n",
    "    name='choropleth',\n",
    "    data=df6,\n",
    "    columns=['dpt_code', 'prop_wom'],\n",
    "    key_on='feature.properties.dpt_code',\n",
    "    fill_color='Reds',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Women Proportion',\n",
    "    missing_kwds= dict(color = \"#DADADB\",)\n",
    ").add_to(map_6)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "map_6.save(\"folium_map.html\")\n",
    "\n",
    "map_6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAP 7\n",
    "# Create a Folium map centered at the mean of the shapefile's coordinates\n",
    "map_center = [dpt_shp.geometry.centroid.y.mean(), dpt_shp.geometry.centroid.x.mean()]\n",
    "Map_7 = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Add the GeoJson layer to the map\n",
    "folium.GeoJson(dpt_shp).add_to(Map_7)\n",
    "\n",
    "# Display the map\n",
    "Map_7"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
