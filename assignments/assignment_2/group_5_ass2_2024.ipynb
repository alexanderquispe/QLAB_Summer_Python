{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 2\n",
    "\n",
    "It is totally prohibited to use any kind of loop. You can use stackoverflow. If you copy codes from previous answers, explain each step. No explanation is `0 points`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Lists\n",
    "1. Show the indices of the `np.nan` values  in the `f_list` list. We want to see this output: `The indices 0, 1, 4, 7 have np.nan values.` **Hint: Use print function and [f-strings](https://realpython.com/python-f-strings/) to insert the indices values.**<br><br>\n",
    "\n",
    "2. Replicate 4 times the values of the list `p2_list`. We expect an ouput like this: `[ 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5]`.  **Hint: Use multiplication function in `lists`and see the output.**<br><br>\n",
    "3. Print the length of `f_list`. **Hint: Length function**<br><br>\n",
    "4. Print `My teacher assistant is so boring.` using `text1` list. **Hint: Use the [`join` function](https://stackoverflow.com/questions/493819/why-is-it-string-joinlist-instead-of-list-joinstring)**<br><br>\n",
    "5. Print `My TA is so boring, but is very funny.` using `text1` list.**Hint: Use the `join` function, and `extend` method.**<br><br>\n",
    "6. Print <br>\n",
    "`The max value of values1 is 86 and is located in the 0 index. ` <br>\n",
    "`The min value of values1 is 0 and is located in the 7 index. ` <br> **Hint: Use the `f-string`, `min`, and `max` functions.**\n",
    "<br>\n",
    "7. Get two lists: `names` and `last_names` using `last_and_name` list. **Hint: Use `map` and `split`.**\n",
    "<br>\n",
    "8. Give only the last names of students who do not have email. Use the `emails` and `last_names` listt. **Hint: Use `map` and `split`.**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan, 'Austria', 'Germany', nan, 'Pakistan', 'np.nan', nan]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pregunta1\n",
    "\n",
    "f_list = [np.nan , np.nan, \"Austria\", \"Germany\", np.nan, \"Pakistan\", \"np.nan\", np.nan ]\n",
    "f_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         NaN\n",
       "2     Austria\n",
       "3     Germany\n",
       "4         NaN\n",
       "5    Pakistan\n",
       "6      np.nan\n",
       "7         NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.Series([np.nan , np.nan, \"Austria\", \"Germany\", np.nan, \"Pakistan\", \"np.nan\", np.nan ])\n",
    "data\n",
    "#Se observa que los índices 0, 1, 4 y 7 contienen el NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pregunta 2\n",
    "p2_list = [ 2 , 3, 4, 5 ]\n",
    "p2_list.extend(p2_list + p2_list + p2_list)\n",
    "p2_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#Pregunta 3\n",
    "print(len(f_list)) # Imprimir la longitud de f_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My teacher assistant is so boring.\n"
     ]
    }
   ],
   "source": [
    "#Pregunta 4\n",
    "text1 = ['My', 'teacher', 'assistant', 'is', 'so', 'boring.']\n",
    "print(' '.join(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My teacher assistant is so boring, but is very funny.\n"
     ]
    }
   ],
   "source": [
    "#Pregunta 5\n",
    "text1 = ['My', 'teacher', 'assistant', 'is', 'so', 'boring,']\n",
    "text1.extend(['but', 'is', 'very', 'funny.']) # Extender la lista con palabras adicionales\n",
    "text1\n",
    "print(' '.join(text1))# Imprimir la frase utilizando join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max value of values1 is 86 and is located in the 0 index.\n"
     ]
    }
   ],
   "source": [
    "#Pregunta 6\n",
    "values1 = [ 86, 86, 85, 85, 85, 83, 23, 0, 84, 1 ] \n",
    "\n",
    "max_value = max(values1)\n",
    "max_value\n",
    "\n",
    "max_index = values1.index(max_value)\n",
    "max_index\n",
    "# Imprimir el valor máximo y su índice\n",
    "print(f\"The max value of values1 is {max_value} and is located in the {max_index} index.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min value of values1 is 0 and is located in the 7 index.\n"
     ]
    }
   ],
   "source": [
    "min_value = min(values1)\n",
    "min_value\n",
    "min_index = values1.index(min_value)\n",
    "min_index\n",
    "# Imprimir el valor mínimo y su índice\n",
    "print(f\"The min value of values1 is {min_value} and is located in the {min_index} index.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names: ['CHRISTIAN SANTOS', 'CRISTIAN NASSER', 'ANGELICA KARINA', 'JOSE ROBERTO', 'ABEL FERNANDO', 'MEIR ALVARO', 'JOSELIN ALEXANDRA', 'LEONEL ARTURO', 'JOSE FELIPE', 'AFRANIA', 'BIANCA MARIETTE', 'ADRIAN ANDRE', 'DORKAS YOMIRA JHERMY', 'LADY ALY', 'HECTOR ANDRE', 'GUSTAVO', 'PERSEO MARCELO', 'MIGUEL ALONZO', 'NICOLAS', 'ROCIO GABRIELA', 'JANE CAMILA', 'MARIA ELISA', 'ALEJANDRO', 'KARLINE ROSMELI', 'STEPHY ROSARIO', 'VALERIA CECILIA', 'SEBASTIAN RENATO', 'JUAN CARLOS', 'MARIANA', 'ANDREA BRIZETH', 'ERICK JOSUE', 'JOSUE DANIEL', 'FABIO MANUEL', 'FERNANDA NICOLLE', 'ANGELA ADELINA', 'CESAR DANTE', 'GABRIELA ISABEL', 'ANGEL MAURICIO', 'JUAN DIEGO', 'ARONE', 'PERCY ALBERTH', 'KEVIN ARTURO', 'CESAR ERNESTO', 'CÉSAR AGUSTO', 'DIANA EDITH', 'RODRIGO FRANCO', 'GRETTEL ALEXANDRA', 'ROSA ANGELA', 'DANTE OMAR', 'YAJAIRA ALEXANDRA', 'JORGE ALBERTO', 'ALEXIS']\n",
      "Last Names: ['CORNEJO SANCHEZ', 'ORELLANA QUISPE', 'MORALES CHOQUEHUANCA', 'GUIMARAY RIBEYRO', 'CAMACHO GAVIDIA', 'TINTAYA ORIHUELA', 'CHAVEZ MARTINEZ', 'FIGUEROA MURO', 'GOMEZ CRIBILLERO', 'PALOMINO SEGUÍN', 'LUZON CUEVA', 'SUAÑA ZEGARRA', 'SOTO POMACHAGUA', 'FIORENTINO MARTINEZ', 'LAMA MAVILA', 'MEZA HINOJO', 'LOZADA MURILLO', 'ZAMBRANO JIMENEZ', 'JACOBS LUQUE', 'VIDAL VIDAL', 'TORRES ANICAMA', 'LOPEZ ESTRADA', 'BOYCO ORAMS', 'DIAZ BERROSPI', 'RIEGA ESCALANTE', 'LEVANO TORRES', 'ESQUIVES BRAVO', 'PEREZ GONZALES', 'OTERO MAGUIÑA', 'CLAVO CAMPOS', 'AGUILAR GARCIA', 'CALDAS VELASQUEZ', 'SALAS NUÑEZ BORJA', 'PIZARRO VILLANES', 'QUILLATUPA MORALES', 'HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'HINOJOSA CAHUANA', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ', 'FLORES CADILLO']\n"
     ]
    }
   ],
   "source": [
    "#Pregunta 7\n",
    "last_and_name = [ \"CORNEJO SANCHEZ, CHRISTIAN SANTOS\", \"ORELLANA QUISPE, CRISTIAN NASSER\", \"MORALES CHOQUEHUANCA, ANGELICA KARINA\", \"GUIMARAY RIBEYRO, JOSE ROBERTO\", \"CAMACHO GAVIDIA, ABEL FERNANDO\", \"TINTAYA ORIHUELA, MEIR ALVARO\", \"CHAVEZ MARTINEZ, JOSELIN ALEXANDRA\", \"FIGUEROA MURO, LEONEL ARTURO\", \"GOMEZ CRIBILLERO, JOSE FELIPE\", \"PALOMINO SEGUÍN, AFRANIA\", \"LUZON CUEVA, BIANCA MARIETTE\", \"SUAÑA ZEGARRA, ADRIAN ANDRE\", \"SOTO POMACHAGUA, DORKAS YOMIRA JHERMY\", \"FIORENTINO MARTINEZ, LADY ALY\", \"LAMA MAVILA, HECTOR ANDRE\", \"MEZA HINOJO, GUSTAVO\", \"LOZADA MURILLO, PERSEO MARCELO\", \"ZAMBRANO JIMENEZ, MIGUEL ALONZO\", \"JACOBS LUQUE, NICOLAS\", \"VIDAL VIDAL, ROCIO GABRIELA\", \"TORRES ANICAMA, JANE CAMILA\", \"LOPEZ ESTRADA, MARIA ELISA\", \"BOYCO ORAMS, ALEJANDRO\", \"DIAZ BERROSPI, KARLINE ROSMELI\", \"RIEGA ESCALANTE, STEPHY ROSARIO\", \"LEVANO TORRES, VALERIA CECILIA\", \"ESQUIVES BRAVO, SEBASTIAN RENATO\", \"PEREZ GONZALES, JUAN CARLOS\", \"OTERO MAGUIÑA, MARIANA\", \"CLAVO CAMPOS, ANDREA BRIZETH\", \"AGUILAR GARCIA, ERICK JOSUE\", \"CALDAS VELASQUEZ, JOSUE DANIEL\", \"SALAS NUÑEZ BORJA, FABIO MANUEL\", \"PIZARRO VILLANES, FERNANDA NICOLLE\", \"QUILLATUPA MORALES, ANGELA ADELINA\", \"HUANCAYA IDONE, CESAR DANTE\", \"CALVO PORTOCARRERO, GABRIELA ISABEL\", \"IBAÑEZ ABANTO, ANGEL MAURICIO\", \"MELÉNDEZ APONTE, JUAN DIEGO\", \"CRISTIAN SERRANO, ARONE\", \"HINOJOSA CAHUANA, PERCY ALBERTH\", \"ANGLAS GARCÍA, KEVIN ARTURO\", \"ALDAVE ACOSTA, CESAR ERNESTO\", \"NÚÑEZ HUAMÁN, CÉSAR AGUSTO\", \"OBREGON HUAMAN, DIANA EDITH\", \"SOTO PACHERRES, RODRIGO FRANCO\", \"INGARUCA RIVERA, GRETTEL ALEXANDRA\", \"ROJAS HUAMAN, ROSA ANGELA\", \"NEYRA SALAS, DANTE OMAR\", \"HUERTA ESPINOZA, YAJAIRA ALEXANDRA\", \"HUANCA MARTINEZ, JORGE ALBERTO\", \"FLORES CADILLO, ALEXIS\" ]\n",
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\", \"\", \"\", \"\", \"\", \"\", \"f0873079@pucp.edu.pe\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"flores.alexis@pucp.edu.pe\", ]\n",
    "\n",
    "# Obtener las listas de nombres y apellidos usando map y split\n",
    "names = list(map(lambda x: x.split(\", \")[1], last_and_name)) #La función split(\", \") divide cada elemento de la lista last_and_name\n",
    "last_names = list(map(lambda x: x.split(\", \")[0], last_and_name)) #La función map extrae la lista de nombres y apellidos\n",
    "\n",
    "# Imprimir las listas resultantes\n",
    "print(\"Names:\", names)\n",
    "print(\"Last Names:\", last_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last names of students who do not have email: ['HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ']\n"
     ]
    }
   ],
   "source": [
    "#Pregunta 8\n",
    "students_without_email = filter(lambda x: x[1] == \"\", zip(last_and_name, emails)) #zip combina las listas last_and_names con emails para luego con el filter seleccionar a los estudiantes sin correo.\n",
    "\n",
    "last_names_without_email = list(map(lambda x: x[0].split(\", \")[0], students_without_email))# Extraer apellidos de estudiantes sin correo electrónico usando map y split\n",
    "\n",
    "print(\"Last names of students who do not have email:\", last_names_without_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Strings\n",
    "\n",
    "\n",
    "1. Drop the duplicated blank spaces in `str1`. Do not use the regular expresions. Do not use the code shown in class. Explain your steps.**Hint: Use `split` method and `join` function.**\n",
    "\n",
    "2. Get the number of letters in the string .**Hint: Use `len`function.**\n",
    "\n",
    "3. Get the number of blank spaces (all of them) in the string .**Hint: Use `len`function.**\n",
    "\n",
    "4. Get the position of `@` in each string in the emails list. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "5. Identifies if exists `.edu.`  in each string in the `emails` list. Get a list of Booleans. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "6. Get all the strings before the first dot `.`in each string in the `emails` list. Identifies how many of them has `@`. **Hint: Use `map`function and `find` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am too old\n"
     ]
    }
   ],
   "source": [
    "#PREGUNTA 1\n",
    "\n",
    "str1 = 'I am                            too                                                        old'\n",
    "\n",
    "# Paso 1: Dividimos la cadena en una lista de palabras.\n",
    "words_list = str1.split()\n",
    "\n",
    "# Paso 2: Filtramos las cadenas vacías de la lista con la función lambda que verifica si una palabra no es una cadena vacía.\n",
    "filtered_words = filter(lambda x: x.strip() != '', words_list)\n",
    "\n",
    "# Paso 3: Unimos las palabras filtradas nuevamente en una cadena con un espacio simple como separador.\n",
    "result_str = ' '.join(filtered_words)\n",
    "\n",
    "# Print de resultados\n",
    "print(result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de letras en la cadena: 9\n"
     ]
    }
   ],
   "source": [
    "#PREGUNTA 2\n",
    "# Se obtiene el número de letras en la cadena\n",
    "num_letters = len([char for char in str1 if char.isalpha()])\n",
    "\n",
    "# Print del resultado\n",
    "print(\"Número de letras en la cadena:\", num_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blank spaces in the string: 85\n"
     ]
    }
   ],
   "source": [
    "#PREGUNTA 3\n",
    "num_spaces = len([char for char in str1 if char.isspace()])\n",
    "print(\"Number of blank spaces in the string:\", num_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions of '@' in each email: [9, 11, 14, 9, 12, 8, 14, 9, 8, 16, 12, 13, 6, 9, 10, 12, 8, 11, 14, 6, 11, 7, 15, 9, 12, 8, 9, 11, 13, 6, 9, 12, 11, 16, 11]\n"
     ]
    }
   ],
   "source": [
    "#PREGUNTA 4\n",
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\"]\n",
    "# Utilizamos un mapa con una función lambda para encontrar la posición de '@' en cada dirección de correo electrónico.\n",
    "positions = list(map(lambda email: email.find('@'), emails))\n",
    "print(\"Positions of '@' in each email:\", positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Booleans indicating if '.edu.' exists in each email: [True, True, True, False, False, True, True, False, False, False, False, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "#PREGUNTA 5\n",
    "# Utilizamos la función map con una función lambda para verificar si \".edu.\" existe en cada dirección de correo electrónico.\n",
    "contains_edu = list(map(lambda email: \".edu.\" in email, emails))\n",
    "print(\"List of Booleans indicating if '.edu.' exists in each email:\", contains_edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of substrings before the first dot: ['cscornejo@pucp', 'orellana', 'karina', 'a20083223@pucp', 'abel', 'mtintaya@pucp', 'joselin', 'a20105737@pucp', 'jfgomezc@pucp', 'afrania', 'luzon', 'adrian', 'soto', 'a20132766@pucp', 'andre', 'gustavo', 'pmlozada@pucp', 'm', 'nicolas', 'gvidal@pucp', 'jane', 'm', 'alejandro', 'a20167070@pucp', 'riega', 'vlevanot@pucp', 'sesquives@pucp', 'perez', 'mariana', 'aclavo@pucp', 'a20182474@pucp', 'josue', 'fabio', 'fernanda', 'aquillatupa@pucp']\n",
      "Number of them containing '@': 14\n"
     ]
    }
   ],
   "source": [
    "#PREGUNTA 6\n",
    "# Utilizamos la función map con una función lambda para obtener la subcadena antes del primer punto en cada caso.\n",
    "substring_before_dot = list(map(lambda email: email[:email.find('.')], emails))\n",
    "# Contamos cuántos de ellos contienen el símbolo @ utilizando la función sum.\n",
    "count_with_at = sum('@' in substring for substring in substring_before_dot)\n",
    "print(\"List of substrings before the first dot:\", substring_before_dot)\n",
    "print(\"Number of them containing '@':\", count_with_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Pandas\n",
    "\n",
    "You can and should always ask ChatGPT, BARD, Bing, etc.\n",
    "In this exercise, you will work with financial data. Follow the steps below:\n",
    "\n",
    "1. Load Data:\n",
    "   Load the financial data available at this URL:    https://raw.githubusercontent.com/datasets/finance-vix/main/data/vix-daily.csv\n",
    "   Use `pd.read_csv()` adn the link to load the data into a DataFrame.\n",
    "\n",
    "2. Explore Data:\n",
    "   a) Display the first five rows of the DataFrame.\n",
    "   b) Display the summary statistics of the DataFrame.\n",
    "\n",
    "3. Add Columns:\n",
    "   a) Add a new column 'Level' that categorizes the 'Close' column values into 'Low' (< 20), 'Medium' (20-30), and 'High' (>30). You need to make a filter to make this categorization. You can see below some suggestions how to do it.\n",
    "   b) Add a new column 'Year' extracted from the 'Date' column. You need to work with dates. You can do it directly workiwith the column splitting it or changing it to date format an dfollowing the below suggestion. \n",
    "\n",
    "4. Add Rows:\n",
    "   a) Add a new row with a date of your choice and fill the other columns with appropriate values. \n",
    "\n",
    "5. Analysis:\n",
    "   a) Calculate the average of the column 'Close' for each 'Year'. You need to group for this task.\n",
    "   b) Count the number of 'High', 'Medium', and 'Low'  Level days in the data.\n",
    "\n",
    "Suggestions:\n",
    "   - Use `pd.cut()` for categorizing 'Close' values.\n",
    "   - Use `pd.to_datetime()` and `dt.year` to extract the year from a date.\n",
    "   - Use `DataFrame.append()` or `pd.concat()` to add rows.\n",
    "   - Use `groupby()` for aggregation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE   OPEN   HIGH    LOW  CLOSE\n",
      "0  01/02/1990  17.24  17.24  17.24  17.24\n",
      "1  01/03/1990  18.19  18.19  18.19  18.19\n",
      "2  01/04/1990  19.22  19.22  19.22  19.22\n",
      "3  01/05/1990  20.11  20.11  20.11  20.11\n",
      "4  01/08/1990  20.26  20.26  20.26  20.26\n"
     ]
    }
   ],
   "source": [
    "# 1) Importando la data usando la librería pandas mostrando las 5 primeras filas\n",
    "import pandas as pd\n",
    "data = pd.read_csv(r'C:\\Users\\User\\Downloads\\assingment 2\\vix-daily.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              OPEN         HIGH          LOW        CLOSE\n",
      "count  8576.000000  8576.000000  8576.000000  8576.000000\n",
      "mean     19.667087    20.475051    18.915540    19.581101\n",
      "std       7.979316     8.440179     7.470016     7.906388\n",
      "min       9.010000     9.310000     8.560000     9.140000\n",
      "25%      13.937500    14.540000    13.407500    13.880000\n",
      "50%      17.795000    18.470000    17.220000    17.760000\n",
      "75%      23.102500    23.960000    22.322500    22.990000\n",
      "max      82.690000    89.530000    72.760000    82.690000\n"
     ]
    }
   ],
   "source": [
    "#2) Resumen estadístico usando data.describe\n",
    "resumen_est = data.describe()\n",
    "print(resumen_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con nuevas columnas y fila:\n",
      "                  DATE   OPEN   HIGH    LOW  CLOSE   Level    Year\n",
      "0  1990-01-02 00:00:00  17.24  17.24  17.24  17.24     Low  1990.0\n",
      "1  1990-01-03 00:00:00  18.19  18.19  18.19  18.19     Low  1990.0\n",
      "2  1990-01-04 00:00:00  19.22  19.22  19.22  19.22     Low  1990.0\n",
      "3  1990-01-05 00:00:00  20.11  20.11  20.11  20.11  Medium  1990.0\n",
      "4  1990-01-08 00:00:00  20.26  20.26  20.26  20.26  Medium  1990.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10156\\3244924114.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(nueva_fila, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# PREGUNTA 3\n",
    "\n",
    "# Se añade la columna Level utilizando pd.cut()\n",
    "bins = [-float('inf'), 20, 30, float('inf')]\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "data['Level'] = pd.cut(data['CLOSE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Se convierte la columna DATE a formato de fecha y extraer el año\n",
    "data['DATE'] = pd.to_datetime(data['DATE'])\n",
    "data['Year'] = data['DATE'].dt.year\n",
    "\n",
    "#PREGUNTA 4\n",
    "\n",
    "# Se añade una nueva fila con una fecha ficticia. En mi caso la siguiente:\n",
    "nueva_fila = pd.DataFrame({'DATE': ['01/15/2024'], 'OPEN': 25.0, 'HIGH': 26.0, 'LOW': 24.5, 'CLOSE': 25.5}, index=[len(data)])\n",
    "data = data.append(nueva_fila, ignore_index=True)\n",
    "\n",
    "# Print de resultados\n",
    "print(\"DataFrame con nuevas columnas y fila:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Promedio de 'CLOSE' por año:\n",
      "Year\n",
      "1990.0    23.063478\n",
      "1991.0    18.373373\n",
      "1992.0    15.452047\n",
      "1993.0    12.686245\n",
      "1994.0    13.925516\n",
      "1995.0    12.388770\n",
      "1996.0    16.442165\n",
      "1997.0    22.363984\n",
      "1998.0    25.602976\n",
      "1999.0    24.371912\n",
      "2000.0    23.315000\n",
      "2001.0    25.749677\n",
      "2002.0    27.292460\n",
      "2003.0    21.982857\n",
      "2004.0    15.479644\n",
      "2005.0    12.807063\n",
      "2006.0    12.810320\n",
      "2007.0    17.535936\n",
      "2008.0    32.695534\n",
      "2009.0    31.479008\n",
      "2010.0    22.548889\n",
      "2011.0    24.202579\n",
      "2012.0    17.801640\n",
      "2013.0    14.230119\n",
      "2014.0    14.175992\n",
      "2015.0    16.674087\n",
      "2016.0    15.825635\n",
      "2017.0    11.090239\n",
      "2018.0    16.639841\n",
      "2019.0    15.387540\n",
      "2020.0    29.251304\n",
      "2021.0    19.656151\n",
      "2022.0    25.637148\n",
      "2023.0    16.849027\n",
      "2024.0    13.790000\n",
      "Name: CLOSE, dtype: float64\n",
      "\n",
      "Conteo de niveles:\n",
      "Low       5271\n",
      "Medium    2583\n",
      "High       722\n",
      "Name: Level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#PREGUNTA 5 (Análisis)\n",
    "\n",
    "# Se calcula el promedio de la columna CLOSE para cada año\n",
    "promedio_por_anio = data.groupby('Year')['CLOSE'].mean()\n",
    "\n",
    "# Se calcula el número de días High, Medium y Low\n",
    "conteo_niveles = data['Level'].value_counts()\n",
    "\n",
    "#Print de resultados\n",
    "print(\"\\nPromedio de 'CLOSE' por año:\")\n",
    "print(promedio_por_anio)\n",
    "\n",
    "print(\"\\nConteo de niveles:\")\n",
    "print(conteo_niveles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
