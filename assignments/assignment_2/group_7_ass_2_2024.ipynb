{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 2\n",
    "\n",
    "It is totally prohibited to use any kind of loop. You can use stackoverflow. If you copy codes from previous answers, explain each step. No explanation is `0 points`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Lists\n",
    "1. Show the indices of the `np.nan` values  in the `f_list` list. We want to see this output: `The indices 0, 1, 4, 7 have np.nan values.` **Hint: Use print function and [f-strings](https://realpython.com/python-f-strings/) to insert the indices values.**<br><br>\n",
    "\n",
    "2. Replicate 4 times the values of the list `p2_list`. We expect an ouput like this: `[ 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5, 2 , 3, 4, 5]`.  **Hint: Use multiplication function in `lists`and see the output.**<br><br>\n",
    "3. Print the length of `f_list`. **Hint: Length function**<br><br>\n",
    "4. Print `My teacher assistant is so boring.` using `text1` list. **Hint: Use the [`join` function](https://stackoverflow.com/questions/493819/why-is-it-string-joinlist-instead-of-list-joinstring)**<br><br>\n",
    "5. Print `My TA is so boring, but is very funny.` using `text1` list.**Hint: Use the `join` function, and `extend` method.**<br><br>\n",
    "6. Print <br>\n",
    "`The max value of values1 is 86 and is located in the 0 index. ` <br>\n",
    "`The min value of values1 is 0 and is located in the 7 index. ` <br> **Hint: Use the `f-string`, `min`, and `max` functions.**\n",
    "<br>\n",
    "7. Get two lists: `names` and `last_names` using `last_and_name` list. **Hint: Use `map` and `split`.**\n",
    "<br>\n",
    "8. Give only the last names of students who do not have email. Use the `emails` and `last_names` listt. **Hint: Use `map` and `split`.**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list = [np.nan , np.nan, \"Austria\", \"Germany\", np.nan, \"Pakistan\", \"np.nan\", np.nan ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ['My', 'teacher', 'assistant', 'is', 'so', 'boring.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_list = [ 2 , 3, 4, 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "values1 = [ 86, 86, 85, 85, 85, 83, 23, 0, 84, 1 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# These two lists a\n",
    "last_and_name = [ \"CORNEJO SANCHEZ, CHRISTIAN SANTOS\", \"ORELLANA QUISPE, CRISTIAN NASSER\", \"MORALES CHOQUEHUANCA, ANGELICA KARINA\", \"GUIMARAY RIBEYRO, JOSE ROBERTO\", \"CAMACHO GAVIDIA, ABEL FERNANDO\", \"TINTAYA ORIHUELA, MEIR ALVARO\", \"CHAVEZ MARTINEZ, JOSELIN ALEXANDRA\", \"FIGUEROA MURO, LEONEL ARTURO\", \"GOMEZ CRIBILLERO, JOSE FELIPE\", \"PALOMINO SEGUÍN, AFRANIA\", \"LUZON CUEVA, BIANCA MARIETTE\", \"SUAÑA ZEGARRA, ADRIAN ANDRE\", \"SOTO POMACHAGUA, DORKAS YOMIRA JHERMY\", \"FIORENTINO MARTINEZ, LADY ALY\", \"LAMA MAVILA, HECTOR ANDRE\", \"MEZA HINOJO, GUSTAVO\", \"LOZADA MURILLO, PERSEO MARCELO\", \"ZAMBRANO JIMENEZ, MIGUEL ALONZO\", \"JACOBS LUQUE, NICOLAS\", \"VIDAL VIDAL, ROCIO GABRIELA\", \"TORRES ANICAMA, JANE CAMILA\", \"LOPEZ ESTRADA, MARIA ELISA\", \"BOYCO ORAMS, ALEJANDRO\", \"DIAZ BERROSPI, KARLINE ROSMELI\", \"RIEGA ESCALANTE, STEPHY ROSARIO\", \"LEVANO TORRES, VALERIA CECILIA\", \"ESQUIVES BRAVO, SEBASTIAN RENATO\", \"PEREZ GONZALES, JUAN CARLOS\", \"OTERO MAGUIÑA, MARIANA\", \"CLAVO CAMPOS, ANDREA BRIZETH\", \"AGUILAR GARCIA, ERICK JOSUE\", \"CALDAS VELASQUEZ, JOSUE DANIEL\", \"SALAS NUÑEZ BORJA, FABIO MANUEL\", \"PIZARRO VILLANES, FERNANDA NICOLLE\", \"QUILLATUPA MORALES, ANGELA ADELINA\", \"HUANCAYA IDONE, CESAR DANTE\", \"CALVO PORTOCARRERO, GABRIELA ISABEL\", \"IBAÑEZ ABANTO, ANGEL MAURICIO\", \"MELÉNDEZ APONTE, JUAN DIEGO\", \"CRISTIAN SERRANO, ARONE\", \"HINOJOSA CAHUANA, PERCY ALBERTH\", \"ANGLAS GARCÍA, KEVIN ARTURO\", \"ALDAVE ACOSTA, CESAR ERNESTO\", \"NÚÑEZ HUAMÁN, CÉSAR AGUSTO\", \"OBREGON HUAMAN, DIANA EDITH\", \"SOTO PACHERRES, RODRIGO FRANCO\", \"INGARUCA RIVERA, GRETTEL ALEXANDRA\", \"ROJAS HUAMAN, ROSA ANGELA\", \"NEYRA SALAS, DANTE OMAR\", \"HUERTA ESPINOZA, YAJAIRA ALEXANDRA\", \"HUANCA MARTINEZ, JORGE ALBERTO\", \"FLORES CADILLO, ALEXIS\" ]\n",
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\", \"\", \"\", \"\", \"\", \"\", \"f0873079@pucp.edu.pe\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"flores.alexis@pucp.edu.pe\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices [0, 1, 4, 7] have np.nan values.\n"
     ]
    }
   ],
   "source": [
    "        # Answer 1\n",
    "\n",
    "nan_values = [i for i, value in enumerate(f_list) if value is np.nan]\n",
    "\n",
    "print(f\"The indices {nan_values} have np.nan values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "        # Answer 2\n",
    "\n",
    "p2_list_2 = p2_list * 4\n",
    "\n",
    "print(p2_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "        # Answer 3\n",
    "\n",
    "print(len(f_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My teacher assistant is so boring.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        # Answer 4\n",
    "\n",
    "answer_4 = ' '.join(text1)\n",
    "answer_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My TA My teacher assistant is so boring but is very funny'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        # Answer 5\n",
    "    \n",
    "text1[-1] = text1[-1].rstrip('.')\n",
    "    \n",
    "text_answer = ['My', 'TA']\n",
    "\n",
    "text_answer_b = ['but', 'is', 'very', 'funny']\n",
    "\n",
    "text_answer.extend(text1 + text_answer_b)\n",
    "\n",
    "answer_5 = ' '.join(text_answer)\n",
    "answer_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max value of values1 is 86 and is located in the 0 index.\n"
     ]
    }
   ],
   "source": [
    "        # Answer 6.1\n",
    "    \n",
    "max_index = values1.index(max(values1))\n",
    "    \n",
    "print(f\"The max value of values1 is {max(values1)} and is located in the {max_index} index.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min value of values1 is 0 and is located in the 7 index.\n"
     ]
    }
   ],
   "source": [
    "        # Answer 6.2\n",
    "    \n",
    "min_index = values1.index(min(values1))\n",
    "    \n",
    "print(f\"The min value of values1 is {min(values1)} and is located in the {min_index} index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names: ('CHRISTIAN SANTOS', 'CRISTIAN NASSER', 'ANGELICA KARINA', 'JOSE ROBERTO', 'ABEL FERNANDO', 'MEIR ALVARO', 'JOSELIN ALEXANDRA', 'LEONEL ARTURO', 'JOSE FELIPE', 'AFRANIA', 'BIANCA MARIETTE', 'ADRIAN ANDRE', 'DORKAS YOMIRA JHERMY', 'LADY ALY', 'HECTOR ANDRE', 'GUSTAVO', 'PERSEO MARCELO', 'MIGUEL ALONZO', 'NICOLAS', 'ROCIO GABRIELA', 'JANE CAMILA', 'MARIA ELISA', 'ALEJANDRO', 'KARLINE ROSMELI', 'STEPHY ROSARIO', 'VALERIA CECILIA', 'SEBASTIAN RENATO', 'JUAN CARLOS', 'MARIANA', 'ANDREA BRIZETH', 'ERICK JOSUE', 'JOSUE DANIEL', 'FABIO MANUEL', 'FERNANDA NICOLLE', 'ANGELA ADELINA', 'CESAR DANTE', 'GABRIELA ISABEL', 'ANGEL MAURICIO', 'JUAN DIEGO', 'ARONE', 'PERCY ALBERTH', 'KEVIN ARTURO', 'CESAR ERNESTO', 'CÉSAR AGUSTO', 'DIANA EDITH', 'RODRIGO FRANCO', 'GRETTEL ALEXANDRA', 'ROSA ANGELA', 'DANTE OMAR', 'YAJAIRA ALEXANDRA', 'JORGE ALBERTO', 'ALEXIS')\n",
      "Last Names: ('CORNEJO SANCHEZ', 'ORELLANA QUISPE', 'MORALES CHOQUEHUANCA', 'GUIMARAY RIBEYRO', 'CAMACHO GAVIDIA', 'TINTAYA ORIHUELA', 'CHAVEZ MARTINEZ', 'FIGUEROA MURO', 'GOMEZ CRIBILLERO', 'PALOMINO SEGUÍN', 'LUZON CUEVA', 'SUAÑA ZEGARRA', 'SOTO POMACHAGUA', 'FIORENTINO MARTINEZ', 'LAMA MAVILA', 'MEZA HINOJO', 'LOZADA MURILLO', 'ZAMBRANO JIMENEZ', 'JACOBS LUQUE', 'VIDAL VIDAL', 'TORRES ANICAMA', 'LOPEZ ESTRADA', 'BOYCO ORAMS', 'DIAZ BERROSPI', 'RIEGA ESCALANTE', 'LEVANO TORRES', 'ESQUIVES BRAVO', 'PEREZ GONZALES', 'OTERO MAGUIÑA', 'CLAVO CAMPOS', 'AGUILAR GARCIA', 'CALDAS VELASQUEZ', 'SALAS NUÑEZ BORJA', 'PIZARRO VILLANES', 'QUILLATUPA MORALES', 'HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'HINOJOSA CAHUANA', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ', 'FLORES CADILLO')\n"
     ]
    }
   ],
   "source": [
    "        # Answer 7\n",
    "\n",
    "last_names, names = zip(*map(lambda x: x.split(', '), last_and_name))\n",
    "                    # the lambda function using split divides each name from each last name\n",
    "                    # the function zip takes the values and puts them in tuples\n",
    "                    # \"last_names, names\" indicates the code to split the tuples in two separate lists\n",
    "print(\"Names:\", names)\n",
    "print(\"Last Names:\", last_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HUANCAYA IDONE', 'CALVO PORTOCARRERO', 'IBAÑEZ ABANTO', 'MELÉNDEZ APONTE', 'CRISTIAN SERRANO', 'ANGLAS GARCÍA', 'ALDAVE ACOSTA', 'NÚÑEZ HUAMÁN', 'OBREGON HUAMAN', 'SOTO PACHERRES', 'INGARUCA RIVERA', 'ROJAS HUAMAN', 'NEYRA SALAS', 'HUERTA ESPINOZA', 'HUANCA MARTINEZ']\n"
     ]
    }
   ],
   "source": [
    "        # Answer 8\n",
    "    \n",
    "answer_8 = [last_name for last_name, email in zip(last_names, emails) if not email]\n",
    "            # zip function pairs last names with its corresponding emails into tuples\n",
    "            # \"last_name for last_name, email in ... if not email\" indicates the last name for each pair if email is empty\n",
    "print(answer_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Strings\n",
    "\n",
    "\n",
    "1. Drop the duplicated blank spaces in `str1`. Do not use the regular expresions. Do not use the code shown in class. Explain your steps.**Hint: Use `split` method and `join` function.**\n",
    "\n",
    "2. Get the number of letters in the string .**Hint: Use `len`function.**\n",
    "\n",
    "3. Get the number of blank spaces (all of them) in the string .**Hint: Use `len`function.**\n",
    "\n",
    "4. Get the position of `@` in each string in the emails list. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "5. Identifies if exists `.edu.`  in each string in the `emails` list. Get a list of Booleans. **Hint: Use `map`function and `find` method.**\n",
    "\n",
    "6. Get all the strings before the first dot `.`in each string in the `emails` list. Identifies how many of them has `@`. **Hint: Use `map`function and `find` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'I am                            too                                                        old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = [\"cscornejo@pucp.edu.pe\", \"orellana.cn@pucp.edu.pe\", \"karina.morales@pucp.edu.pe\", \"a20083223@pucp.pe\", \"abel.camacho@pucp.pe\", \"mtintaya@pucp.edu.pe\", \"joselin.chavez@pucp.edu.pe\", \"a20105737@pucp.pe\", \"jfgomezc@pucp.pe\", \"afrania.palomino@pucp.pe\", \"luzon.bianca@pucp.pe\", \"adrian.suanaz@pucp.pe\", \"soto.y@pucp.edu.pe\", \"a20132766@pucp.pe\", \"andre.lama@pucp.edu.pe\", \"gustavo.meza@pucp.edu.pe\", \"pmlozada@pucp.edu.pe\", \"m.zambranoj@pucp.edu.pe\", \"nicolas.jacobs@pucp.edu.pe\", \"gvidal@pucp.edu.pe\", \"jane.torres@pucp.edu.pe\", \"m.lopez@pucp.edu.pe\", \"alejandro.boyco@pucp.edu.pe\", \"a20167070@pucp.edu.pe\", \"riega.stephy@pucp.edu.pe\", \"vlevanot@pucp.edu.pe\", \"sesquives@pucp.edu.pe\", \"perez.juanc@pucp.edu.pe\", \"mariana.otero@pucp.edu.pe\", \"aclavo@pucp.edu.pe\", \"a20182474@pucp.edu.pe\", \"josue.caldas@pucp.edu.pe\", \"fabio.salas@pucp.edu.pe\", \"fernanda.pizarro@pucp.edu.pe\", \"aquillatupa@pucp.pe\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Pandas\n",
    "\n",
    "You can and should always ask ChatGPT, BARD, Bing, etc.\n",
    "In this exercise, you will work with financial data. Follow the steps below:\n",
    "\n",
    "1. Load Data:\n",
    "   Load the financial data available at this URL:    https://raw.githubusercontent.com/datasets/finance-vix/main/data/vix-daily.csv\n",
    "   Use `pd.read_csv()` adn the link to load the data into a DataFrame.\n",
    "\n",
    "2. Explore Data:\n",
    "   a) Display the first five rows of the DataFrame.\n",
    "   b) Display the summary statistics of the DataFrame.\n",
    "\n",
    "3. Add Columns:\n",
    "   a) Add a new column 'Level' that categorizes the 'Close' column values into 'Low' (< 20), 'Medium' (20-30), and 'High' (>30). You need to make a filter to make this categorization. You can see below some suggestions how to do it.\n",
    "   b) Add a new column 'Year' extracted from the 'Date' column. You need to work with dates. You can do it directly workiwith the column splitting it or changing it to date format an dfollowing the below suggestion. \n",
    "\n",
    "4. Add Rows:\n",
    "   a) Add a new row with a date of your choice and fill the other columns with appropriate values. \n",
    "\n",
    "5. Analysis:\n",
    "   a) Calculate the average of the column 'Close' for each 'Year'. You need to group for this task.\n",
    "   b) Count the number of 'High', 'Medium', and 'Low'  Level days in the data.\n",
    "\n",
    "Suggestions:\n",
    "   - Use `pd.cut()` for categorizing 'Close' values.\n",
    "   - Use `pd.to_datetime()` and `dt.year` to extract the year from a date.\n",
    "   - Use `DataFrame.append()` or `pd.concat()` to add rows.\n",
    "   - Use `groupby()` for aggregation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This code loads the data from the provided URL.\n",
    "url = \"https://raw.githubusercontent.com/datasets/finance-vix/main/data/vix-daily.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/1990</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/03/1990</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/04/1990</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/05/1990</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/08/1990</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>12/28/2023</td>\n",
       "      <td>12.44</td>\n",
       "      <td>12.65</td>\n",
       "      <td>12.38</td>\n",
       "      <td>12.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>12/29/2023</td>\n",
       "      <td>12.55</td>\n",
       "      <td>13.19</td>\n",
       "      <td>12.36</td>\n",
       "      <td>12.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>01/02/2024</td>\n",
       "      <td>13.22</td>\n",
       "      <td>14.23</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>01/03/2024</td>\n",
       "      <td>13.35</td>\n",
       "      <td>14.22</td>\n",
       "      <td>13.33</td>\n",
       "      <td>14.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>01/04/2024</td>\n",
       "      <td>13.93</td>\n",
       "      <td>14.20</td>\n",
       "      <td>13.64</td>\n",
       "      <td>14.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8576 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE   OPEN   HIGH    LOW  CLOSE\n",
       "0     01/02/1990  17.24  17.24  17.24  17.24\n",
       "1     01/03/1990  18.19  18.19  18.19  18.19\n",
       "2     01/04/1990  19.22  19.22  19.22  19.22\n",
       "3     01/05/1990  20.11  20.11  20.11  20.11\n",
       "4     01/08/1990  20.26  20.26  20.26  20.26\n",
       "...          ...    ...    ...    ...    ...\n",
       "8571  12/28/2023  12.44  12.65  12.38  12.47\n",
       "8572  12/29/2023  12.55  13.19  12.36  12.45\n",
       "8573  01/02/2024  13.22  14.23  13.10  13.20\n",
       "8574  01/03/2024  13.35  14.22  13.33  14.04\n",
       "8575  01/04/2024  13.93  14.20  13.64  14.13\n",
       "\n",
       "[8576 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We check the data assigned to the variable 'df'.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras cinco filas del DataFrame:\n",
      "         DATE   OPEN   HIGH    LOW  CLOSE\n",
      "0  01/02/1990  17.24  17.24  17.24  17.24\n",
      "1  01/03/1990  18.19  18.19  18.19  18.19\n",
      "2  01/04/1990  19.22  19.22  19.22  19.22\n",
      "3  01/05/1990  20.11  20.11  20.11  20.11\n",
      "4  01/08/1990  20.26  20.26  20.26  20.26\n",
      "\n",
      "Estadísticas resumidas del DataFrame:\n",
      "              OPEN         HIGH          LOW        CLOSE\n",
      "count  8577.000000  8577.000000  8577.000000  8577.000000\n",
      "mean     19.666454    20.474364    18.914884    19.580374\n",
      "std       7.979066     8.439927     7.469827     7.906214\n",
      "min       9.010000     9.310000     8.560000     9.140000\n",
      "25%      13.940000    14.540000    13.400000    13.880000\n",
      "50%      17.790000    18.470000    17.220000    17.760000\n",
      "75%      23.100000    23.960000    22.320000    22.990000\n",
      "max      82.690000    89.530000    72.760000    82.690000\n"
     ]
    }
   ],
   "source": [
    "# We display the first five rows of the DataFrame.\n",
    "print(\"Primeras cinco filas del DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# We display the summarized statistics of the DataFrame.\n",
    "print(\"\\nEstadísticas resumidas del DataFrame:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>Level</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/1990</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>Low</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/03/1990</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>Low</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/04/1990</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>Low</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/05/1990</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/08/1990</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>12/29/2023</td>\n",
       "      <td>12.55</td>\n",
       "      <td>13.19</td>\n",
       "      <td>12.36</td>\n",
       "      <td>12.45</td>\n",
       "      <td>Low</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>01/02/2024</td>\n",
       "      <td>13.22</td>\n",
       "      <td>14.23</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.20</td>\n",
       "      <td>Low</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>01/03/2024</td>\n",
       "      <td>13.35</td>\n",
       "      <td>14.22</td>\n",
       "      <td>13.33</td>\n",
       "      <td>14.04</td>\n",
       "      <td>Low</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>01/04/2024</td>\n",
       "      <td>13.93</td>\n",
       "      <td>14.20</td>\n",
       "      <td>13.64</td>\n",
       "      <td>14.13</td>\n",
       "      <td>Low</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8576</th>\n",
       "      <td>01/05/2024</td>\n",
       "      <td>14.24</td>\n",
       "      <td>14.58</td>\n",
       "      <td>13.29</td>\n",
       "      <td>13.35</td>\n",
       "      <td>Low</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8577 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE   OPEN   HIGH    LOW  CLOSE   Level  Year\n",
       "0     01/02/1990  17.24  17.24  17.24  17.24     Low  1990\n",
       "1     01/03/1990  18.19  18.19  18.19  18.19     Low  1990\n",
       "2     01/04/1990  19.22  19.22  19.22  19.22     Low  1990\n",
       "3     01/05/1990  20.11  20.11  20.11  20.11  Medium  1990\n",
       "4     01/08/1990  20.26  20.26  20.26  20.26  Medium  1990\n",
       "...          ...    ...    ...    ...    ...     ...   ...\n",
       "8572  12/29/2023  12.55  13.19  12.36  12.45     Low  2023\n",
       "8573  01/02/2024  13.22  14.23  13.10  13.20     Low  2024\n",
       "8574  01/03/2024  13.35  14.22  13.33  14.04     Low  2024\n",
       "8575  01/04/2024  13.93  14.20  13.64  14.13     Low  2024\n",
       "8576  01/05/2024  14.24  14.58  13.29  13.35     Low  2024\n",
       "\n",
       "[8577 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We add a 'Level' column to categorize the 'CLOSE' values\n",
    "df['Level'] = pd.cut(df['CLOSE'], bins=[-float('inf'), 20, 30, float('inf')],\n",
    "                                  labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# We add the 'Year' column extracted from the 'DATE' column, keeping only the year using the dt.year function.\n",
    "# Firstly, the 'DATE' variable was categorized as datetime.\n",
    "df['Year'] = pd.to_datetime(df['DATE']).dt.year\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>Level</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/1990</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>17.24</td>\n",
       "      <td>Low</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/03/1990</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>18.19</td>\n",
       "      <td>Low</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/04/1990</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>19.22</td>\n",
       "      <td>Low</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/05/1990</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>20.11</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/08/1990</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.26</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>01/02/2024</td>\n",
       "      <td>13.22</td>\n",
       "      <td>14.23</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.20</td>\n",
       "      <td>Low</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>01/03/2024</td>\n",
       "      <td>13.35</td>\n",
       "      <td>14.22</td>\n",
       "      <td>13.33</td>\n",
       "      <td>14.04</td>\n",
       "      <td>Low</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>01/04/2024</td>\n",
       "      <td>13.93</td>\n",
       "      <td>14.20</td>\n",
       "      <td>13.64</td>\n",
       "      <td>14.13</td>\n",
       "      <td>Low</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8576</th>\n",
       "      <td>01/05/2024</td>\n",
       "      <td>14.24</td>\n",
       "      <td>14.58</td>\n",
       "      <td>13.29</td>\n",
       "      <td>13.35</td>\n",
       "      <td>Low</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8577</th>\n",
       "      <td>01/06/2024</td>\n",
       "      <td>14.27</td>\n",
       "      <td>14.61</td>\n",
       "      <td>13.32</td>\n",
       "      <td>13.38</td>\n",
       "      <td>Low</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8578 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE   OPEN   HIGH    LOW  CLOSE   Level  Year\n",
       "0     01/02/1990  17.24  17.24  17.24  17.24     Low  1990\n",
       "1     01/03/1990  18.19  18.19  18.19  18.19     Low  1990\n",
       "2     01/04/1990  19.22  19.22  19.22  19.22     Low  1990\n",
       "3     01/05/1990  20.11  20.11  20.11  20.11  Medium  1990\n",
       "4     01/08/1990  20.26  20.26  20.26  20.26  Medium  1990\n",
       "...          ...    ...    ...    ...    ...     ...   ...\n",
       "8573  01/02/2024  13.22  14.23  13.10  13.20     Low  2024\n",
       "8574  01/03/2024  13.35  14.22  13.33  14.04     Low  2024\n",
       "8575  01/04/2024  13.93  14.20  13.64  14.13     Low  2024\n",
       "8576  01/05/2024  14.24  14.58  13.29  13.35     Low  2024\n",
       "8577  01/06/2024  14.27  14.61  13.32  13.38     Low  2024\n",
       "\n",
       "[8578 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temporalmente eliminamos las columnas 'Level' y 'Year' para evitar NaN en el df\n",
    "df = df.drop(['Level', 'Year'], axis=1)\n",
    "\n",
    "# Agregamos la nueva fila solicitada\n",
    "new_row = pd.DataFrame({'DATE': ['01/06/2024'],  \n",
    "                        'OPEN': [14.27],            \n",
    "                        'HIGH': [14.61],            \n",
    "                        'LOW': [13.32],           \n",
    "                        'CLOSE': [13.38]})      \n",
    "\n",
    "# Agregamos la nueva fila al DataFrame existente\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# Recategorizamos 'Level' y 'Year' después de agregar la nueva fila\n",
    "df['Level'] = pd.cut(df['CLOSE'], bins=[-float('inf'), 20, 30, float('inf')],\n",
    "                                  labels=['Low', 'Medium', 'High'])\n",
    "df['Year'] = pd.to_datetime(df['DATE']).dt.year\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "1990    23.06\n",
       "1991    18.37\n",
       "1992    15.45\n",
       "1993    12.69\n",
       "1994    13.93\n",
       "1995    12.39\n",
       "1996    16.44\n",
       "1997    22.36\n",
       "1998    25.60\n",
       "1999    24.37\n",
       "2000    23.32\n",
       "2001    25.75\n",
       "2002    27.29\n",
       "2003    21.98\n",
       "2004    15.48\n",
       "2005    12.81\n",
       "2006    12.81\n",
       "2007    17.54\n",
       "2008    32.70\n",
       "2009    31.48\n",
       "2010    22.55\n",
       "2011    24.20\n",
       "2012    17.80\n",
       "2013    14.23\n",
       "2014    14.18\n",
       "2015    16.67\n",
       "2016    15.83\n",
       "2017    11.09\n",
       "2018    16.64\n",
       "2019    15.39\n",
       "2020    29.25\n",
       "2021    19.66\n",
       "2022    25.64\n",
       "2023    16.85\n",
       "2024    13.62\n",
       "Name: CLOSE, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos el promedio de la columna 'Close' para cada 'Year'\n",
    "average_close_by_year = df.groupby('Year')['CLOSE'].mean().round(2)\n",
    "average_close_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Level\n",
       "Low       5276\n",
       "Medium    2582\n",
       "High       720\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contamos el número de días con niveles 'High', 'Medium' y 'Low'\n",
    "count_levels = df.groupby('Level').size()\n",
    "count_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
